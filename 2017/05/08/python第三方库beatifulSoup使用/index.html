<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>python第三方库beatifulSoup使用 | CallteFoot&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="python中BeautifulSoup使用&amp;ensp;&amp;ensp;BeautifulSoup是一个可以从Html或xml文件中提取数据的python库，它能够通过不同的转换器实现惯用的文档导航、查找、修改文档的方式。&amp;ensp;&amp;ensp;首先看看它的一些基本用法：123456789101112131415161718192021222324252627282930313233343536373">
<meta name="keywords">
<meta property="og:type" content="article">
<meta property="og:title" content="python第三方库beatifulSoup使用">
<meta property="og:url" content="https://cattlefoot.github.io/2017/05/08/python第三方库beatifulSoup使用/index.html">
<meta property="og:site_name" content="CallteFoot's blog">
<meta property="og:description" content="python中BeautifulSoup使用&amp;ensp;&amp;ensp;BeautifulSoup是一个可以从Html或xml文件中提取数据的python库，它能够通过不同的转换器实现惯用的文档导航、查找、修改文档的方式。&amp;ensp;&amp;ensp;首先看看它的一些基本用法：123456789101112131415161718192021222324252627282930313233343536373">
<meta property="og:updated_time" content="2017-05-10T13:46:25.346Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python第三方库beatifulSoup使用">
<meta name="twitter:description" content="python中BeautifulSoup使用&amp;ensp;&amp;ensp;BeautifulSoup是一个可以从Html或xml文件中提取数据的python库，它能够通过不同的转换器实现惯用的文档导航、查找、修改文档的方式。&amp;ensp;&amp;ensp;首先看看它的一些基本用法：123456789101112131415161718192021222324252627282930313233343536373">
  
    <link rel="alternate" href="/atom.xml" title="CallteFoot&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">CallteFoot&#39;s blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://cattlefoot.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python第三方库beatifulSoup使用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/05/08/python第三方库beatifulSoup使用/" class="article-date">
  <time datetime="2017-05-08T15:03:56.000Z" itemprop="datePublished">2017-05-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python第三方库beatifulSoup使用
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="python中BeautifulSoup使用"><a href="#python中BeautifulSoup使用" class="headerlink" title="python中BeautifulSoup使用"></a>python中BeautifulSoup使用</h1><p>&ensp;&ensp;BeautifulSoup是一个可以从Html或xml文件中提取数据的python库，它能够通过不同的转换器实现惯用的文档导航、查找、修改文档的方式。<br>&ensp;&ensp;首先看看它的一些基本用法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># !/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">from</span> BeautifulSoup <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line">html_doc = <span class="string">"""&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></div><div class="line"></div><div class="line">&lt;body&gt;</div><div class="line"></div><div class="line">&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</div><div class="line"></div><div class="line">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;,</div><div class="line"></div><div class="line">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</div><div class="line"></div><div class="line">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</div><div class="line"></div><div class="line">and they lived at the bottom of a well.&lt;/p&gt;</div><div class="line">&lt;p class="story"&gt;...&lt;/p&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;"""</div><div class="line">soup = BeautifulSoup(html_doc)</div><div class="line"><span class="comment"># 通过prettify方法格式化文档</span></div><div class="line"><span class="comment"># print(soup.prettify())</span></div><div class="line"><span class="comment"># 输出文件对象的title标签内容</span></div><div class="line"><span class="keyword">print</span> soup.title</div><div class="line"><span class="comment"># 输出标签的名字</span></div><div class="line"><span class="keyword">print</span> soup.title.name</div><div class="line"><span class="comment"># 输出标签的文本内容</span></div><div class="line"><span class="keyword">print</span> soup.title.string</div><div class="line"><span class="comment"># 输出标签title的父节点名字</span></div><div class="line"><span class="keyword">print</span> soup.title.parent.name</div><div class="line"><span class="comment"># 输出标签的属性class的值,!前提是该标签有定义了该属性，要不会报错</span></div><div class="line"><span class="keyword">print</span> soup.p[<span class="string">"class"</span>]</div><div class="line"><span class="comment"># 输出文档中所有a标签的节点</span></div><div class="line"><span class="keyword">print</span> soup.findAll(<span class="string">"a"</span>)</div><div class="line"><span class="comment"># 输出节点带有id属性且id属性值为"link3"的节点</span></div><div class="line"><span class="keyword">print</span> soup.find(id=<span class="string">"link3"</span>)</div><div class="line"><span class="comment"># 从文档中找到所有a标签的链接</span></div><div class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.findAll(<span class="string">"a"</span>):</div><div class="line">    print(link.get(<span class="string">"href"</span>))</div><div class="line"><span class="comment"># 从文档中获取所有文字内容,text属性是调用getText()方法,getText()方法可以添加分隔符,有的本版是这个方法名：get_text()</span></div><div class="line">print(soup.text)</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;大致浏览了下BeautifulSoup用法，接着我们看看如何在中用。</p>
<p>#首先是安装</p>
<ol>
<li><p>ubuntu或者Debain系统安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ apt-get install Python-bs4</div></pre></td></tr></table></figure>
</li>
<li><p>直接命令安装，Beautiful Soup 4 通过PyPi发布,所以如果你无法使用系统包管理安装，那么也可以通过 easy_install 或 pip 来安装。包的名字是 beautifulsoup4 ，这个包兼容Python2和Python3。</p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function">c:\&gt; <span class="title">easy_install</span> <span class="title">beautifulsoup4</span></span></div><div class="line"><span class="title">c</span>:\&gt; <span class="title">pip</span> <span class="title">install</span> <span class="title">beautifulsoup4</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>&ensp;&ensp;<strong>注意</strong>在PyPi中还有一个名字是 BeautifulSoup 的包，但那可能不是你想要的,那是 Beautiful Soup3 的发布版本，因为很多项目还在使用BS3, 所以 BeautifulSoup 包依然有效。但是如果你在编写新项目，那么你应该安装的 beautifulsoup4。</p>
<ol>
<li><p>通过下载<a href="http://www.crummy.com/software/BeautifulSoup/download/4.x/" target="_blank" rel="external">源码</a>安装，解压进入源码包，然后运行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python setup.py install</div></pre></td></tr></table></figure>
</li>
<li><p>通过ide辅助安装，在代码中输入一下内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 版本 3.x.x引入方式</span></div><div class="line"><span class="keyword">from</span> BeautifulSoup <span class="keyword">import</span> BeautifulSoup</div></pre></td></tr></table></figure>
</li>
</ol>
<p>或者<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 版本4以上含，引入方式</span></div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;然后ide会提示BeautifulSoup找不到，再根据提示安装即可。</p>
<p><strong>安装完成后可能遇到的问题</strong></p>
<hr>
<ol>
<li>代码中抛出ImportError的异常：“No module named HTMLParser”，这是因为你在Python3版本中执行Python2版本的代码。</li>
<li>代码抛出了 ImportError 的异常: “No module named html.parser”, 这是因为你在Python2版本中执行Python3版本的代码.<br>&ensp;&ensp;如果遇到上述2种情况,最好的解决方法是重新安装BeautifulSoup4。</li>
</ol>
<p>#安装解析器<br>&ensp;&ensp;Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器,其中一个是 lxml .根据操作系统不同,可以选择下列方法来安装lxml:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ apt-get install Python-lxml</div><div class="line">$ easy_install lxml</div><div class="line">$ pip install lxml</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;另一个可供选择的解析器是纯Python实现的 html5lib , html5lib的解析方式与浏览器相同,可以选择下列方法来安装html5lib:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ apt-get install Python-html5lib</div><div class="line">$ easy_install html5lib</div><div class="line">$ pip install html5lib</div></pre></td></tr></table></figure></p>
<p>python中主要的一些解析器和各自优缺点：</p>
<table>
<thead>
<tr>
<th style="text-align:left">解析器</th>
<th style="text-align:left">使用方法</th>
<th style="text-align:left">优势</th>
<th style="text-align:left">劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Python标准库</td>
<td style="text-align:left">BeautifulSoup(markup, “html.parser”)</td>
<td style="text-align:left">Python的内置标准库;执行速度适中;文档容错能力强</td>
<td style="text-align:left">Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差</td>
</tr>
<tr>
<td style="text-align:left">lxml HTML 解析器</td>
<td style="text-align:left">BeautifulSoup(markup, “lxml”)</td>
<td style="text-align:left">速度快;文档容错能力强</td>
<td style="text-align:left">需要安装C语言库</td>
</tr>
<tr>
<td style="text-align:left">lxml XML 解析器</td>
<td style="text-align:left">BeautifulSoup(markup, [“lxml-xml”])<br>BeautifulSoup(markup, “xml”)</td>
<td style="text-align:left">速度快;唯一支持XML的解析器</td>
<td style="text-align:left">需要安装C语言库</td>
</tr>
<tr>
<td style="text-align:left">html5lib</td>
<td style="text-align:left">BeautifulSoup(markup, “html5lib”)</td>
<td style="text-align:left">最好的容错性;以浏览器的方式解析文档;生成HTML5格式的文档</td>
<td style="text-align:left">速度慢;不依赖外部扩展</td>
</tr>
</tbody>
</table>
<p>&ensp;&ensp;推荐使用lxml作为解析器,因为效率更高. 在Python2.7.3之前的版本和Python3中3.2.2之前的版本,必须安装lxml或html5lib, 因为那些Python版本的标准库中内置的HTML解析方法不够稳定.</p>
<p>&ensp;&ensp;<strong>提示</strong> 如果一段HTML或XML文档格式不正确的话,那么在不同的解析器中返回的结果可能是不一样的,查看 [解析器之间的区别] (<a href="http://doc.iplaypy.com/bs4/#id49)了解更多细节。" target="_blank" rel="external">http://doc.iplaypy.com/bs4/#id49)了解更多细节。</a></p>
<p>#使用<br>&ensp;&ensp;将一段文档传入BeautifulSoup 的构造方法,就能得到一个文档的对象, 可以传入一段字符串或一个文件句柄。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line">soup = BeautifulSoup(open(<span class="string">"index.html"</span>))</div><div class="line">soup = BeautifulSoup(<span class="string">"&lt;html&gt;data&lt;/html&gt;"</span>)</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;首先文档被转换成Unicode,并且HTML的实例都被转换成Unicode编码，然后，Beautiful Soup选择最合适的解析器来解析这段文档，如果手动指定解析器那么Beautiful Soup会选择指定的解析器来解析文档。</p>
<p>##对象的种类<br>&ensp;&ensp;Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象，所有对象可以归纳为4种: Tag ，NavigableString ，BeautifulSoup，Comment 。</p>
<p>###Tag<br>&ensp;&ensp;Tag 对象与XML或HTML原生文档中的tag相同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">'&lt;b class="boldest"&gt;Extremely bold&lt;/b&gt;'</span>)</div><div class="line">tag = soup.b</div><div class="line">type(tag)</div><div class="line"><span class="comment"># &lt;class 'bs4.element.Tag'&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;Tag有很多方法和属性，在遍历文档树和搜索文档树中有详细解释。现在介绍一下tag中最重要的属性: name和attributes</p>
<ol>
<li><p><strong>Name</strong>：每个tag都有自己的名字，通过 .name 来获取:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tag.name</div><div class="line"><span class="comment"># u'b'</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>Attributes</strong>：一个tag可能有很多个属性.。tag <b class="boldest"> 有一个 “class” 的属性，值为 “boldest” 。 tag的属性的操作方法与字典相同:</b></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tag[<span class="string">'class'</span>]</div><div class="line"><span class="comment"># u'boldest'</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>也可以直接”点“取属性，比如：.attrs:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tag.attrs</div><div class="line"><span class="comment"># &#123;u'class': u'boldest'&#125;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;tag的属性可以被添加,删除或修改。<strong>tag的属性操作方法与字典一样</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">tag[<span class="string">'class'</span>] = <span class="string">'verybold'</span></div><div class="line">tag[<span class="string">'id'</span>] = <span class="number">1</span></div><div class="line">tag</div><div class="line"><span class="comment"># &lt;blockquote class="verybold" id="1"&gt;Extremely bold&lt;/blockquote&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">del</span> tag[<span class="string">'class'</span>]</div><div class="line"><span class="keyword">del</span> tag[<span class="string">'id'</span>]</div><div class="line">tag</div><div class="line"><span class="comment"># &lt;blockquote&gt;Extremely bold&lt;/blockquote&gt;</span></div><div class="line"></div><div class="line">tag[<span class="string">'class'</span>]</div><div class="line"><span class="comment"># KeyError: 'class'</span></div><div class="line"></div><div class="line">print(tag.get(<span class="string">'class'</span>))</div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<ol>
<li>多值属性：HTML 4定义了一系列可以包含多个值的属性。在HTML5中移除了一些，却增加更多。最常见的多值的属性是 class (一个tag可以有多个CSS的class). 、。还有一些属性 rel , rev , accept-charset , headers , accesskey 。在Beautiful Soup中多值属性的返回类型是list:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">css_soup = BeautifulSoup(<span class="string">'&lt;p class="body strikeout"&gt;&lt;/p&gt;'</span>)</div><div class="line">css_soup.p[<span class="string">'class'</span>]</div><div class="line"><span class="comment"># ["body", "strikeout"]</span></div><div class="line"></div><div class="line">css_soup = BeautifulSoup(<span class="string">'&lt;p class="body"&gt;&lt;/p&gt;'</span>)</div><div class="line">css_soup.p[<span class="string">'class'</span>]</div><div class="line"><span class="comment"># ["body"]</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>&ensp;&ensp;如果某个属性看起来好像有多个值,但在任何版本的HTML定义中都没有被定义为多值属性,那么Beautiful Soup会将这个属性作为字符串返回。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">id_soup = BeautifulSoup(<span class="string">'&lt;p id="my id"&gt;&lt;/p&gt;'</span>)</div><div class="line">id_soup.p[<span class="string">'id'</span>]</div><div class="line"><span class="comment"># 'my id'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;将tag转换成字符串时,多值属性会合并为一个值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">rel_soup = BeautifulSoup(<span class="string">'&lt;p&gt;Back to the &lt;a rel="index"&gt;homepage&lt;/a&gt;&lt;/p&gt;'</span>)</div><div class="line">rel_soup.a[<span class="string">'rel'</span>]</div><div class="line"><span class="comment"># ['index']</span></div><div class="line"></div><div class="line">rel_soup.a[<span class="string">'rel'</span>] = [<span class="string">'index'</span>, <span class="string">'contents'</span>]</div><div class="line">print(rel_soup.p)</div><div class="line"><span class="comment"># &lt;p&gt;Back to the &lt;a rel="index contents"&gt;homepage&lt;/a&gt;&lt;/p&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果转换的文档是XML格式，那么tag中不包含多值属性。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">xml_soup = BeautifulSoup(<span class="string">'&lt;p class="body strikeout"&gt;&lt;/p&gt;'</span>, <span class="string">'xml'</span>)</div><div class="line"></div><div class="line">xml_soup.p[<span class="string">'class'</span>]</div><div class="line"><span class="comment"># u'body strikeout'</span></div></pre></td></tr></table></figure></p>
<p>###NavigableString:可以遍历的字符串<br>&ensp;&ensp;字符串常被包含在tag内。Beautiful Soup用 NavigableString 类来包装tag中的字符串:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tag.string</div><div class="line"><span class="comment"># u'Extremely bold'</span></div><div class="line"></div><div class="line">type(tag.string)</div><div class="line"><span class="comment"># &lt;class 'bs4.element.NavigableString'&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;一个 NavigableString 字符串与Python中的Unicode字符串相同,并且还支持包含在 遍历文档树 和 搜索文档树 中的一些特性. 通过 unicode() 方法可以直接将 NavigableString 对象转换成Unicode字符串:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">unicode_string = unicode(tag.string)</div><div class="line"></div><div class="line">unicode_string</div><div class="line"><span class="comment"># u'Extremely bold'</span></div><div class="line"></div><div class="line">type(unicode_string)</div><div class="line"><span class="comment"># &lt;type 'unicode'&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replaceWith() 方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tag.string.replaceWith(<span class="string">"No longer bold"</span>)</div><div class="line"></div><div class="line">tag</div><div class="line"><span class="comment"># &lt;blockquote&gt;No longer bold&lt;/blockquote&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;NavigableString 对象支持 遍历文档树 和 搜索文档树 中定义的大部分属性, 并非全部。尤其是一个字符串不能包含其它内容(tag能够包含字符串或是其它tag)，字符串不支持 .contents 或 .string 属性或 find() 方法。<br>&ensp;&ensp;如果想在Beautiful Soup之外使用 NavigableString 对象，需要调用 unicode() 方法，将该对象转换成普通的Unicode字符串，否则就算Beautiful Soup的方法已经执行结束,该对象的输出也会带有对象的引用地址，这样会浪费内存。</p>
<p>###BeautifulSoup<br>&ensp;&ensp;BeautifulSoup 对象表示的是一个文档的全部内容。大部分时候，可以把它当作 Tag 对象，它支持遍历文档树 和 搜索文档树 中描述的大部分的方法。<br>&ensp;&ensp;因为 BeautifulSoup 对象并不是真正的HTML或XML的tag，所以它没有name和attribute属性。但有时查看它的 .name 属性是很方便的，所以 BeautifulSoup 对象包含了一个值为 “[document]” 的特殊属性 .name。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">soup.name</div><div class="line"><span class="comment"># u'[document]'</span></div></pre></td></tr></table></figure></p>
<p>###Comment<br>&ensp;&ensp;注释及特殊字符串,Tag , NavigableString , BeautifulSoup 几乎覆盖了html和xml中的所有内容，但是还有一些特殊对象。容易让人担心的内容是文档的注释部分:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;"</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">comment = soup.b.string</div><div class="line"></div><div class="line">type(comment)</div><div class="line"><span class="comment"># &lt;class 'bs4.element.Comment'&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;Comment 对象是一个特殊类型的 NavigableString 对象:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">comment</div><div class="line"><span class="comment"># u'Hey, buddy. Want to buy a used parser'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;但是当它出现在HTML文档中时, Comment 对象会使用特殊的格式输出:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(soup.b.prettify())</div><div class="line"><span class="comment"># &lt;b&gt;</span></div><div class="line"><span class="comment">#  &lt;!--Hey, buddy. Want to buy a used parser?--&gt;</span></div><div class="line"><span class="comment"># &lt;/b&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;Beautiful Soup中定义的其它类型都可能会出现在XML的文档中: CData , ProcessingInstruction , Declaration , Doctype 。与 Comment 对象类似，这些类都是 NavigableString 的子类，只是添加了一些额外的方法的字符串独享。下面是用CDATA来替代注释的例子:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> CData</div><div class="line">cdata = CData(<span class="string">"A CDATA block"</span>)</div><div class="line">comment.replaceWith(cdata)</div><div class="line"></div><div class="line">print(soup.b.prettify())</div><div class="line"><span class="comment"># &lt;b&gt;</span></div><div class="line"><span class="comment">#  &lt;![CDATA[A CDATA block]]&gt;</span></div><div class="line"><span class="comment"># &lt;/b&gt;</span></div></pre></td></tr></table></figure></p>
<p>##遍历文档树<br>&ensp;&ensp;还拿开头的html_doc文档来做例子</p>
<p>###子节点<br>&ensp;&ensp;一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.Beautiful Soup提供了许多操作和遍历子节点的属性.<br><strong>注意:</strong> Beautiful Soup中字符串节点不支持这些属性，因为字符串没有子节点。</p>
<ol>
<li>tag的名字</li>
</ol>
<p>&ensp;&ensp;操作文档树最简单的方法就是告诉它你想获取的tag的name.如果想获取 <head> 标签,只要用 soup.head :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.head</div><div class="line"><span class="comment"># &lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></div><div class="line"></div><div class="line">soup.title</div><div class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></div></pre></td></tr></table></figure></head></p>
<p>&ensp;&ensp;这是个获取tag的小窍门，可以在文档树的tag中多次调用这个方法。下面的代码可以获取<body>标签中的第一个<b>标签：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">soup.body.b</div><div class="line"><span class="comment"># &lt;b&gt;The Dormouse's story&lt;/b&gt;</span></div></pre></td></tr></table></figure></b></body></p>
<p>&ensp;&ensp;通过<strong>点</strong>取属性的方式<strong>只能获得当前名字的第一个tag</strong>:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">soup.a</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果想要得到所有的<a>标签，或是通过名字得到比一个tag更多的内容的时候，就需要用到 Searching the tree 中描述的方法，比如: find_all()<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">'a'</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></a></p>
<ol>
<li>.contents 和 .children</li>
</ol>
<p>&ensp;&ensp;tag的 .contents 属性可以将tag的子节点以列表的方式输出:<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">head_tag = soup.head</div><div class="line">head_tag</div><div class="line"># &lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</div><div class="line"></div><div class="line">head_tag.contents</div><div class="line">[&lt;title&gt;The Dormouse's story&lt;/title&gt;]</div><div class="line"></div><div class="line">title_tag = head_tag.contents[0]</div><div class="line">title_tag</div><div class="line"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</div><div class="line"></div><div class="line">title_tag.contents</div><div class="line"># [u'The Dormouse's story']</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;BeautifulSoup 对象本身一定会包含子节点，也就是说<html>标签也是 BeautifulSoup 对象的子节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">len(soup.contents)</div><div class="line"><span class="comment"># 1</span></div><div class="line">soup.contents[<span class="number">0</span>].name</div><div class="line"><span class="comment"># u'html'</span></div></pre></td></tr></table></figure></html></p>
<p>&ensp;&ensp;字符串没有 .contents 属性,因为字符串没有子节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">text = title_tag.contents[<span class="number">0</span>]</div><div class="line">text.contents</div><div class="line"><span class="comment"># AttributeError: 'NavigableString' object has no attribute 'contents'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;通过tag的 .children 生成器,可以对tag的子节点进行循环:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> child <span class="keyword">in</span> title_tag.children:</div><div class="line">    print(child)</div><div class="line">    <span class="comment"># The Dormouse's story</span></div></pre></td></tr></table></figure></p>
<ol>
<li>.descendants</li>
</ol>
<p>&ensp;&ensp;.contents 和 .children 属性仅包含tag的直接子节点。例如，<head>标签只有一个直接子节点<title><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">head_tag.contents</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div></pre></td></tr></table></figure></title></head></p>
<p>&ensp;&ensp;但是<title>标签也包含一个子节点:字符串 “The Dormouse’s story”,这种情况下字符串 “The Dormouse’s story”也属于<head>标签的子孙节点. .descendants 属性可以对所有tag的子孙节点进行递归循环 :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> child <span class="keyword">in</span> head_tag.descendants:</div><div class="line">    print(child)</div><div class="line">    <span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></div><div class="line">    <span class="comment"># The Dormouse's story</span></div></pre></td></tr></table></figure></head></title></p>
<ol>
<li>.string</li>
</ol>
<p>&ensp;&ensp;如果tag<strong>只有一个 NavigableString 类型子节点</strong>,那么这个tag可以使用 .string 得到子节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">title_tag.string</div><div class="line"><span class="comment"># u'The Dormouse's story'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">head_tag.contents</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div><div class="line"></div><div class="line">head_tag.string</div><div class="line"><span class="comment"># u'The Dormouse's story'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(soup.html.string)</div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<ol>
<li>.stings和stipped_strings<br>&ensp;&ensp;如果tag中包含多个字符串 ,可以使用 .strings 来循环获取:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> string <span class="keyword">in</span> soup.strings:</div><div class="line">    print(repr(string))</div><div class="line">    </div><div class="line">    <span class="comment"># u"The Dormouse's story"</span></div><div class="line">    <span class="comment"># u'\n\n'</span></div><div class="line">    <span class="comment"># u"The Dormouse's story"</span></div><div class="line">    <span class="comment"># u'\n\n'</span></div><div class="line">    <span class="comment"># u'Once upon a time there were three little sisters; and their names were\n'</span></div><div class="line">    <span class="comment"># u'Elsie'</span></div><div class="line">    <span class="comment"># u',\n'</span></div><div class="line">    <span class="comment"># u'Lacie'</span></div><div class="line">    <span class="comment"># u' and\n'</span></div><div class="line">    <span class="comment"># u'Tillie'</span></div><div class="line">    <span class="comment"># u';\nand they lived at the bottom of a well.'</span></div><div class="line">    <span class="comment"># u'\n\n'</span></div><div class="line">    <span class="comment"># u'...'</span></div><div class="line">    <span class="comment"># u'\n'</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>&ensp;&ensp;输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> string <span class="keyword">in</span> soup.stripped_strings:</div><div class="line">    print(repr(string))</div><div class="line">    <span class="comment"># u"The Dormouse's story"</span></div><div class="line">    <span class="comment"># u"The Dormouse's story"</span></div><div class="line">    <span class="comment"># u'Once upon a time there were three little sisters; and their names were'</span></div><div class="line">    <span class="comment"># u'Elsie'</span></div><div class="line">    <span class="comment"># u','</span></div><div class="line">    <span class="comment"># u'Lacie'</span></div><div class="line">    <span class="comment"># u'and'</span></div><div class="line">    <span class="comment"># u'Tillie'</span></div><div class="line">    <span class="comment"># u';\nand they lived at the bottom of a well.'</span></div><div class="line">    <span class="comment"># u'...'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;全部是空格的行会被忽略掉,段首和段末的空白会被删除。</p>
<p>###父节点<br>&ensp;&ensp;每个tag或字符串都有父节点:被包含在某个tag中.</p>
<ol>
<li>.parent </li>
</ol>
<p>&ensp;&ensp;通过 .parent 属性来获取某个元素的父节点.在例子“爱丽丝”的文档中,<head>标签是<title>标签的父节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">title_tag = soup.title</div><div class="line">title_tag</div><div class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></div><div class="line"></div><div class="line">title_tag.parent</div><div class="line"><span class="comment"># &lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></div></pre></td></tr></table></figure></title></head></p>
<p>&ensp;&ensp;文档title的字符串也有父节点:<title>标签<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">title_tag.string.parent</div><div class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></div></pre></td></tr></table></figure></title></p>
<p>&ensp;&ensp;文档的顶层节点比如<html>的父节点是 BeautifulSoup 对象:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">html_tag = soup.html</div><div class="line">type(html_tag.parent)</div><div class="line"><span class="comment"># &lt;class 'bs4.BeautifulSoup'&gt;</span></div></pre></td></tr></table></figure></html></p>
<p>&ensp;&ensp;BeautifulSoup 对象的 .parent 是None:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(soup.parent)</div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<ol>
<li>.parents</li>
</ol>
<p>&ensp;&ensp;通过元素的 .parents 属性可以递归得到元素的所有父辈节点,下面的例子使用了 .parents 方法遍历了a标签到根节点的所有节点。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">link = soup.a</div><div class="line">link</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;</span></div><div class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> link.parents:</div><div class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        print(parent)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        print(parent.name)</div><div class="line"><span class="comment"># p</span></div><div class="line"><span class="comment"># body</span></div><div class="line"><span class="comment"># html</span></div><div class="line"><span class="comment"># [document]</span></div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<p>###兄弟节点<br>&ensp;&ensp;节点同属于同一个元素的子节点,那么这些节点可以被称为兄弟节点。一段文档以标准格式输出时，兄弟节点有相同的缩进级别。在代码中也可以使用这种关系。</p>
<ol>
<li>.next_sibling和.previous_sibling</li>
</ol>
<p>&ensp;&ensp;在文档树中,使用 .next_sibling 和 .previous_sibling 属性来查询兄弟节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sibling_soup = BeautifulSoup(<span class="string">"&lt;a&gt;&lt;b&gt;text1&lt;/b&gt;&lt;c&gt;text2&lt;/c&gt;&lt;/b&gt;&lt;/a&gt;"</span>)</div><div class="line"></div><div class="line"><span class="keyword">print</span> sibling_soup.b.next_sibling</div><div class="line"><span class="comment"># &lt;c&gt;text2&lt;/c&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">print</span> sibling_soup.c.previous_sibling</div><div class="line"><span class="comment"># &lt;b&gt;text1&lt;/b&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;b标签有 .next_sibling 属性,但是没有 .previous_sibling 属性,因为b标签在同级节点中是第一个.同理,c标签有 .previous_sibling 属性,却没有 .next_sibling 属性:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">print(sibling_soup.b.previous_sibling)</div><div class="line"><span class="comment"># None</span></div><div class="line"></div><div class="line">print(sibling_soup.c.next_sibling)</div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;例子中的字符串“text1”和“text2”不是兄弟节点,因为它们的父节点不同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sibling_soup.b.string</div><div class="line"><span class="comment"># u'text1'</span></div><div class="line"></div><div class="line">print(sibling_soup.b.string.next_sibling)</div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<ol>
<li>.next_siblings 和 .previous_siblings</li>
</ol>
<p>&ensp;&ensp;通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</div><div class="line">    print(repr(sibling))</div><div class="line"></div><div class="line">    <span class="comment"># u',\n'</span></div><div class="line">    <span class="comment"># &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;</span></div><div class="line">    <span class="comment"># u' and\n'</span></div><div class="line">    <span class="comment"># &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;</span></div><div class="line">    <span class="comment"># u'; and they lived at the bottom of a well.'</span></div><div class="line">    <span class="comment"># None</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.find(id=<span class="string">"link3"</span>).previous_siblings:</div><div class="line">    print(repr(sibling))</div><div class="line">    </div><div class="line">    <span class="comment"># ' and\n'</span></div><div class="line">    <span class="comment"># &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;</span></div><div class="line">    <span class="comment"># u',\n'</span></div><div class="line">    <span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;</span></div><div class="line">    <span class="comment"># u'Once upon a time there were three little sisters; and their names were\n'</span></div><div class="line">    <span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<p>###回退和前进</p>
<ol>
<li>.next_element 和 .previous_element<br>&ensp;&ensp;.next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),结果可能与 .next_sibling 相同,但通常是不一样的.<br>&ensp;&ensp;这是“爱丽丝”文档中最后一个a标签,它的 .next_sibling 结果是一个字符串,因为当前的解析过程 [2] 因为当前的解析过程因为遇到了a标签而中断了:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">last_a_tag = soup.find(<span class="string">"a"</span>, id=<span class="string">"link3"</span>)</div><div class="line"><span class="keyword">print</span> last_a_tag</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">print</span> last_a_tag.next_sibling</div><div class="line"><span class="comment"># '; and they lived at the bottom of a well.'</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>&ensp;&ensp;但这个a标签的 .next_element 属性结果是在a标签被解析之后的解析内容，不是a标签后的句子部分,应该是字符串”Tillie”:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> last_a_tag.next_element</div><div class="line"><span class="comment"># u'Tillie'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;这是因为在原始文档中,字符串“Tillie” 在分号前出现,解析器先进入a标签,然后是字符串“Tillie”,然后关闭a标签,然后是分号和剩余部分.分号与a标签在同一层级,但是字符串“Tillie”会被先解析.</p>
<p>&ensp;&ensp;.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> last_a_tag.previous_element</div><div class="line"><span class="comment"># u' and\n'</span></div><div class="line"></div><div class="line"><span class="keyword">print</span> last_a_tag.previous_element.next_element</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<ol>
<li>.next_elements 和 .previous_elements</li>
</ol>
<p>&ensp;&ensp;通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> element <span class="keyword">in</span> last_a_tag.next_elements:</div><div class="line">    print(repr(element))</div><div class="line"><span class="comment"># u'Tillie'</span></div><div class="line"><span class="comment"># u';\nand they lived at the bottom of a well.'</span></div><div class="line"><span class="comment"># u'\n\n'</span></div><div class="line"><span class="comment"># &lt;p class="story"&gt;...&lt;/p&gt;</span></div><div class="line"><span class="comment"># u'...'</span></div><div class="line"><span class="comment"># u'\n'</span></div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<p>###搜索文档树<br>&ensp;&ensp;Beautiful Soup定义了很多搜索方法，这里着重介绍2个: find() 和 find_all() ，其它方法的参数和用法类似,请读者举一反三。</p>
<ol>
<li>过滤器</li>
</ol>
<p>&ensp;&ensp;介绍 find_all() 方法前，先介绍一下过滤器的类型 ，这些过滤器贯穿整个搜索的API。过滤器可以被用在tag的name中,节点的属性中，字符串中或他们的混合中。</p>
<ul>
<li>字符串：最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的b标签:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">'b'</span>)</div><div class="line"><span class="comment"># [&lt;b&gt;The Dormouse's story&lt;/b&gt;]</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>&ensp;&ensp;如果传入字节码参数，Beautiful Soup会当作UTF-8编码，可以传入一段Unicode 编码来避免Beautiful Soup解析编码出错。</p>
<ul>
<li>正则表达式：如果传入正则表达式作为参数，Beautiful Soup会通过正则表达式的 match() 来匹配内容。下面例子中找出所有以b开头的标签,这表示body和b标签都应该被找到:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">"^b"</span>)):</div><div class="line">    print(tag.name)</div><div class="line"><span class="comment"># body</span></div><div class="line"><span class="comment"># b</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>下面代码找出所有名字中包含”t”的标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">"t"</span>)):</div><div class="line">    print(tag.name)</div><div class="line"></div><div class="line"><span class="comment"># html</span></div><div class="line"><span class="comment"># title</span></div></pre></td></tr></table></figure></p>
<ol>
<li>列表 </li>
</ol>
<p>&ensp;&ensp;如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有a标签和b标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">soup.find_all([<span class="string">"a"</span>, <span class="string">"b"</span>])</div><div class="line"></div><div class="line"><span class="comment"># [&lt;b&gt;The Dormouse's story&lt;/b&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>True</li>
</ol>
<p>&ensp;&ensp;True 可以匹配任何值,下面代码查找到所有的tag，但是不会返回字符串节点。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(<span class="keyword">True</span>):</div><div class="line">    print(tag.name)</div><div class="line">    </div><div class="line"><span class="comment"># html</span></div><div class="line"><span class="comment"># head</span></div><div class="line"><span class="comment"># title</span></div><div class="line"><span class="comment"># body</span></div><div class="line"><span class="comment"># p</span></div><div class="line"><span class="comment"># b</span></div><div class="line"><span class="comment"># p</span></div><div class="line"><span class="comment"># a</span></div><div class="line"><span class="comment"># a</span></div><div class="line"><span class="comment"># a</span></div><div class="line"><span class="comment"># p</span></div></pre></td></tr></table></figure></p>
<ol>
<li>方法</li>
</ol>
<p>&ensp;&ensp;如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数  ，如果这个方法返回 True 表示当前元素匹配并且被找到，如果不是则反回 False。<br>&ensp;&ensp;下面方法校验了当前元素，如果包含 class 属性却不包含 id 属性，那么将返回 True:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">has_class_but_no_id</span><span class="params">(tag)</span>:</span></div><div class="line">    <span class="keyword">return</span> tag.has_attr(<span class="string">'class'</span>) <span class="keyword">and</span> <span class="keyword">not</span> tag.has_attr(<span class="string">'id'</span>)</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;将这个方法作为参数传入 find_all() 方法,将得到所有p标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.find_all(has_class_but_no_id)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;,</span></div><div class="line"><span class="comment">#  &lt;p class="story"&gt;Once upon a time there were...&lt;/p&gt;,</span></div><div class="line"><span class="comment">#  &lt;p class="story"&gt;...&lt;/p&gt;]</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;返回结果中只有p标签没有a标签,因为a标签还定义了”id”,没有返回html和head，因为html和head中没有定义”class”属性.<br>&ensp;&ensp;通过一个方法来过滤一类标签属性的时候, 这个方法的参数是要被过滤的属性的值, 而不是这个标签. 下面的例子是找出 href 属性不符合指定正则的 a 标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">not_lacie</span><span class="params">(href)</span>:</span></div><div class="line">        <span class="keyword">return</span> href <span class="keyword">and</span> <span class="keyword">not</span> re.compile(<span class="string">"lacie"</span>).search(href)</div><div class="line">        </div><div class="line">soup.find_all(href=not_lacie)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;标签过滤方法可以使用复杂方法. 下面的例子可以过滤出前后都有文字的标签.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> NavigableString</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">surrounded_by_strings</span><span class="params">(tag)</span>:</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> (isinstance(tag.next_element, NavigableString)</div><div class="line"></div><div class="line">            <span class="keyword">and</span> isinstance(tag.previous_element, NavigableString))</div><div class="line"></div><div class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(surrounded_by_strings):</div><div class="line">    <span class="keyword">print</span> tag.name</div><div class="line"></div><div class="line"><span class="comment"># p</span></div><div class="line"><span class="comment"># a</span></div><div class="line"><span class="comment"># a</span></div><div class="line"><span class="comment"># a</span></div><div class="line"><span class="comment"># p</span></div></pre></td></tr></table></figure></p>
<p>##find_all()方法剖析<br>find_all( name , attrs , recursive , string , **kwargs )</p>
<p>find_all() 方法搜索当前tag的所有tag子节点，并判断是否符合过滤器的条件。</p>
<ol>
<li>name参数</li>
</ol>
<p>&ensp;&ensp;name 参数可以查找所有名字为 name 的tag，字符串对象会被自动忽略掉。<br>&ensp;&ensp;<strong>重申:</strong> 搜索 name 参数的值可以使任一类型的 过滤器 ，字符窜，正则表达式，列表，方法或是 True 。</p>
<ol>
<li>keyword 参数</li>
</ol>
<p>&ensp;&ensp;如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数，Beautiful Soup会搜索每个tag的”id”属性：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">soup.find_all(id=<span class="string">'link2'</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果传入 href 参数，Beautiful Soup会搜索每个tag的”href”属性:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">soup.find_all(href=re.compile(<span class="string">"elsie"</span>))</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;<strong>重申:</strong>搜索指定名字的属性时可以使用的参数值包括 字符串 , 正则表达式 , 列表, True 。<br>&ensp;&ensp;使用多个指定名字的参数可以同时过滤tag的多个属性:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">soup.find_all(href=re.compile(<span class="string">"elsie"</span>), id=<span class="string">'link1'</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;three&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>attrs<br>&ensp;&ensp;有些tag属性在搜索不能使用,比如HTML5中的 data-* 属性:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">data_soup = BeautifulSoup(<span class="string">'&lt;div data-foo="value"&gt;foo!&lt;/div&gt;'</span>)</div><div class="line">data_soup.find_all(data-foo=<span class="string">"value"</span>)</div><div class="line"><span class="comment"># SyntaxError: keyword can't be an expression</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>&ensp;&ensp;但是可以通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data_soup.find_all(attrs=&#123;<span class="string">"data-foo"</span>: <span class="string">"value"</span>&#125;)</div><div class="line"><span class="comment"># [&lt;div data-foo="value"&gt;foo!&lt;/div&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>按CSS搜索</li>
</ol>
<p>&ensp;&ensp;按照CSS类名搜索tag的功能非常实用，但标识CSS类名的关键字 class 在Python中是保留字，使用 class 做参数会导致语法错误.从Beautiful Soup的4.1.1版本开始,可以通过 class_ 参数搜索有指定CSS类名的tag:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">"a"</span>, class_=<span class="string">"sister"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p><strong>重申:</strong>class_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">soup.find_all(class_=re.compile(<span class="string">"itl"</span>))</div><div class="line"><span class="comment"># [&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;]</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">has_six_characters</span><span class="params">(css_class)</span>:</span></div><div class="line">    <span class="keyword">return</span> css_class <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">and</span> len(css_class) == <span class="number">6</span></div><div class="line"></div><div class="line">soup.find_all(class_=has_six_characters)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;tag的 class 属性是 多值属性 。按照CSS类名搜索tag时，可以分别搜索tag中的每个CSS类名:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">css_soup = BeautifulSoup(<span class="string">'&lt;p class="body strikeout"&gt;&lt;/p&gt;'</span>)</div><div class="line"></div><div class="line">css_soup.find_all(<span class="string">"p"</span>, class_=<span class="string">"strikeout"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;p class="body strikeout"&gt;&lt;/p&gt;]</span></div><div class="line">css_soup.find_all(<span class="string">"p"</span>, class_=<span class="string">"body"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;p class="body strikeout"&gt;&lt;/p&gt;]</span></div></pre></td></tr></table></figure></p>
<p>搜索 class 属性时也可以通过CSS值完全匹配:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">css_soup.find_all(<span class="string">"p"</span>, class_=<span class="string">"body strikeout"</span>)</div><div class="line"><span class="comment"># [&lt;p class="body strikeout"&gt;&lt;/p&gt;]</span></div></pre></td></tr></table></figure></p>
<p>完全匹配 class 的值时，如果CSS类名的顺序与实际不符，将搜索不到结果:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">"a"</span>, attrs=&#123;<span class="string">"class"</span>: <span class="string">"sister"</span>&#125;)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>string 参数</li>
</ol>
<p>&ensp;&ensp;通过 string 参数可以搜搜文档中的字符串内容。与 name 参数的可选值一样,，<strong>重申</strong>string 参数接受 字符串 , 正则表达式 , 列表, True . 看例子:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">soup.find_all(string=<span class="string">"Elsie"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [u'Elsie']</span></div><div class="line"></div><div class="line">soup.find_all(string=[<span class="string">"Tillie"</span>, <span class="string">"Elsie"</span>, <span class="string">"Lacie"</span>])</div><div class="line"><span class="comment"># [u'Elsie', u'Lacie', u'Tillie']</span></div><div class="line"></div><div class="line">soup.find_all(string=re.compile(<span class="string">"Dormouse"</span>))</div><div class="line"></div><div class="line">[<span class="string">u"The Dormouse's story"</span>, <span class="string">u"The Dormouse's story"</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_the_only_string_within_a_tag</span><span class="params">(s)</span>:</span></div><div class="line"></div><div class="line">    <span class="string">""</span>Return <span class="keyword">True</span> <span class="keyword">if</span> this string <span class="keyword">is</span> the only child of its parent tag.<span class="string">""</span></div><div class="line">    <span class="keyword">return</span> (s == s.parent.string)</div><div class="line"></div><div class="line">soup.find_all(string=is_the_only_string_within_a_tag)</div><div class="line"><span class="comment"># [u"The Dormouse's story", u"The Dormouse's story", u'Elsie', u'Lacie', u'Tillie', u'...']</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;虽然 string 参数用于搜索字符串，还可以与其它参数混合使用来过滤tag。Beautiful Soup会找到 .string 方法与 string 参数值相符的tag.下面代码用来搜索内容里面包含“Elsie”的a标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">"a"</span>, string=<span class="string">"Elsie"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>limit 参数</li>
</ol>
<p>&ensp;&ensp;find_all() 方法返回全部的搜索结构，如果文档树很大那么搜索会很慢；如果我们不需要全部结果，可以使用 limit 参数限制返回结果的数量。效果与SQL中的limit关键字类似，当搜索到的结果数量达到 limit 的限制时，就停止搜索返回结果。<br>&ensp;&ensp;文档树中有3个tag符合搜索条件,但结果只返回了2个,因为我们限制了返回数量:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">"a"</span>, limit=<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>recuresive参数<br>&ensp;&ensp;调用tag的 find_all() 方法时，Beautiful Soup会检索当前tag的所有子孙节点，如果只想搜索tag的直接子节点，可以使用参数 recursive=False 。<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.html.find_all(<span class="string">"title"</span>)</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div><div class="line"></div><div class="line">soup.html.find_all(<span class="string">"title"</span>, recursive=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># []</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>注意</strong>Beautiful Soup 提供了多种DOM树搜索方法。这些方法都使用了类似的参数定义。 比如这些方法: find_all(): name, attrs, text, limit. 但是只有 find_all() 和 find() 支持 recursive 参数。</p>
<ol>
<li>像调用 find_all() 一样调用tag</li>
</ol>
<p>&ensp;&ensp;find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">"a"</span>)</div><div class="line">soup(<span class="string">"a"</span>)</div><div class="line"></div><div class="line">soup.title.find_all(string=<span class="keyword">True</span>)</div><div class="line">soup.title(string=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p>
<p>##find()方法剖析<br>find( name , attrs , recursive , string , **kwargs )</p>
<p>&ensp;&ensp;find_all() 方法将返回文档中符合条件的所有tag，尽管有时候我们只想得到一个结果.比如文档中只有一个<body>标签,那么使用 find_all() 方法来查找body标签就不太合适， 使用 find_all 方法并设置 limit=1 参数不如直接使用 find() 方法。下面两行代码是等价的:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.find_all(<span class="string">'title'</span>, limit=<span class="number">1</span>)</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div><div class="line"></div><div class="line">soup.find(<span class="string">'title'</span>)</div><div class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></div></pre></td></tr></table></figure></body></p>
<p>&ensp;&ensp;唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表，而 find() 方法直接返回结果。<br>&ensp;&ensp;find_all() 方法没有找到目标是返回空列表，find() 方法找不到目标时，返回 None 。</p>
<p>##find_parents() 和 find_parent()<br>find_parents( name , attrs , recursive , string , <strong>kwargs )<br>find_parent( name , attrs , recursive , string , </strong>kwargs )</p>
<p>&ensp;&ensp;我们已经用了很大篇幅来介绍 find_all() 和 find() 方法,Beautiful Soup中还有10个用于搜索的API.它们中的五个用的是与 find_all() 相同的搜索参数,另外5个与 find() 方法的搜索参数类似.区别仅是它们搜索文档的不同部分.</p>
<p>&ensp;&ensp;记住: find_all() 和 find() 只搜索当前节点的所有子节点,孙子节点等. find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同,搜索文档搜索文档包含的内容. 我们从一个文档中的一个叶子节点开始:<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">a_string = soup.find(string="Lacie")</div><div class="line"></div><div class="line">a_string</div><div class="line"></div><div class="line"># u'Lacie'</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">a_string.find_parents("a")</div><div class="line"></div><div class="line"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">a_string.find_parent("p")</div><div class="line"></div><div class="line"># &lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</div><div class="line"></div><div class="line">#  &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</div><div class="line"></div><div class="line">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt; and</div><div class="line"></div><div class="line">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;;</div><div class="line"></div><div class="line">#  and they lived at the bottom of a well.&lt;/p&gt;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">a_string.find_parents("p", class="title")</div><div class="line"></div><div class="line"># []</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;文档中的一个a标签是是当前叶子节点的直接父节点,所以可以被找到.还有一个p标签,是目标叶子节点的间接父辈节点,所以也可以被找到.包含class值为”title”的p标签不是不是目标叶子节点的父辈节点,所以通过 find_parents() 方法搜索不到.</p>
<p>&ensp;&ensp;find_parent() 和 find_parents() 方法会让人联想到 .parent 和 .parents 属性.它们之间的联系非常紧密.搜索父辈节点的方法实际上就是对 .parents 属性的迭代搜索.</p>
<p>##find_next_siblings()和find_next_sibling()<br>find_next_siblings( name , attrs , recursive , string , **kwargs )</p>
<p>find_next_sibling( name , attrs , recursive , string , **kwargs )</p>
<p>&ensp;&ensp;这2个方法通过 .next_siblings 属性对当tag的所有后面解析 的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.</p>
<p>##find_previous_siblings() 和 find_previous_sibling()<br>find_previous_siblings( name , attrs , recursive , string , <strong>kwargs )<br>find_previous_sibling( name , attrs , recursive , string , </strong>kwargs )</p>
<p>&ensp;&ensp;这2个方法通过 .previous_siblings 属性对当前tag的前面解析 的兄弟tag节点进行迭代, find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">last_link = soup.find(<span class="string">"a"</span>, id=<span class="string">"link3"</span>)</div><div class="line"></div><div class="line">last_link</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;</span></div><div class="line"></div><div class="line">last_link.find_previous_siblings(<span class="string">"a"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">first_story_paragraph = soup.find(<span class="string">"p"</span>, <span class="string">"story"</span>)</div><div class="line">first_story_paragraph.find_previous_sibling(<span class="string">"p"</span>)</div><div class="line"><span class="comment"># &lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></div></pre></td></tr></table></figure></p>
<p>##find_all_next() 和 find_next()<br>&ensp;&ensp;这2个方法通过 .next_elements 属性对当前tag的之后的 tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">first_link = soup.a</div><div class="line">first_link</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;</span></div><div class="line"></div><div class="line">first_link.find_all_next(string=<span class="keyword">True</span>)</div><div class="line"><span class="comment"># [u'Elsie', u',\n', u'Lacie', u' and\n', u'Tillie',</span></div><div class="line"><span class="comment">#  u';\nand they lived at the bottom of a well.', u'\n\n', u'...', u'\n']</span></div><div class="line"></div><div class="line">first_link.find_next(<span class="string">"p"</span>)</div><div class="line"><span class="comment"># &lt;p class="story"&gt;...&lt;/p&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;第一个例子中,字符串 “Elsie”也被显示出来,尽管它被包含在我们开始查找的a标签的里面.第二个例子中,最后一个p标签也被显示出来,尽管它与我们开始查找位置的a标签不属于同一部分.例子中,搜索的重点是要匹配过滤器的条件,并且在文档中出现的顺序而不是开始查找的元素的位置.</p>
<p>##find_all_previous() 和 find_previous()<br>find_all_previous( name , attrs , recursive , string , <strong>kwargs )<br>find_previous( name , attrs , recursive , string , </strong>kwargs )</p>
<p>&ensp;&ensp;这2个方法通过 .previous_elements 属性对当前节点前面 的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">first_link = soup.a</div><div class="line">first_link</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;</span></div><div class="line"></div><div class="line">first_link.find_all_previous(<span class="string">"p"</span>)</div><div class="line"><span class="comment"># [&lt;p class="story"&gt;Once upon a time there were three little sisters; ...&lt;/p&gt;,</span></div><div class="line"><span class="comment">#  &lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;]</span></div><div class="line"></div><div class="line">first_link.find_previous(<span class="string">"title"</span>)</div><div class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;find_all_previous(“p”) 返回了文档中的第一段(class=”title”的那段),但还返回了第二段,p标签包含了我们开始查找的a标签.不要惊讶,这段代码的功能是查找所有出现在指定a标签之前的p标签,因为这个p标签包含了开始的a标签,所以p标签一定是在a之前出现的.</p>
<p>##CSS选择器<br>Beautiful Soup支持大部分的CSS<a href="http://www.w3.org/TR/CSS2/selector.html" target="_blank" rel="external">选择器</a> , 在 Tag 或 BeautifulSoup 对象的 .select() 方法中传入字符串参数, 即可使用CSS选择器的语法找到tag:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">"title"</span>)</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"p nth-of-type(3)"</span>)</div><div class="line"><span class="comment"># [&lt;p class="story"&gt;...&lt;/p&gt;]</span></div></pre></td></tr></table></figure></p>
<p>通过tag标签逐层查找:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">"body a"</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie"  id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"html head title"</span>)</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div></pre></td></tr></table></figure></p>
<p>找到某个tag标签下的直接子标签 :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">"head &gt; title"</span>)</div><div class="line"><span class="comment"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"p &gt; a"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie"  id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"p &gt; a:nth-of-type(2)"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"p &gt; #link1"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"body &gt; a"</span>)</div><div class="line"><span class="comment"># []</span></div></pre></td></tr></table></figure></p>
<p>找到兄弟节点标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">"#link1 ~ .sister"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie"  id="link3"&gt;Tillie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"#link1 + .sister"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>通过CSS的类名查找:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">通过CSS的类名查找:</div><div class="line"></div><div class="line">soup.select(<span class="string">".sister"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"[class~=sister]"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>通过tag的id查找:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">"#link1"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">"a#link2"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>同时用多种CSS选择器查询元素:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">"#link1,#link2"</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>通过是否存在某个属性来查找:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">'a[href]'</span>)</div><div class="line"></div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>通过属性的值来查找:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">soup.select(<span class="string">'a[href="http://example.com/elsie"]'</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">'a[href^="http://example.com/"]'</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></div><div class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">'a[href$="tillie"]'</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></div><div class="line"></div><div class="line">soup.select(<span class="string">'a[href*=".com/el"]'</span>)</div><div class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;]</span></div></pre></td></tr></table></figure></p>
<p>通过语言设置来查找:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">multilingual_markup = <span class="string">"""</span></div><div class="line"> &lt;p lang="en"&gt;Hello&lt;/p&gt;</div><div class="line"> &lt;p lang="en-us"&gt;Howdy, y'all&lt;/p&gt;</div><div class="line"> &lt;p lang="en-gb"&gt;Pip-pip, old fruit&lt;/p&gt;</div><div class="line"> &lt;p lang="fr"&gt;Bonjour mes amis&lt;/p&gt;</div><div class="line">"""</div><div class="line"></div><div class="line">multilingual_soup = BeautifulSoup(multilingual_markup)</div><div class="line">multilingual_soup.select(<span class="string">'p[lang|=en]'</span>)</div><div class="line"><span class="comment"># [&lt;p lang="en"&gt;Hello&lt;/p&gt;,</span></div><div class="line"><span class="comment">#  &lt;p lang="en-us"&gt;Howdy, y'all&lt;/p&gt;,</span></div><div class="line"><span class="comment">#  &lt;p lang="en-gb"&gt;Pip-pip, old fruit&lt;/p&gt;]</span></div></pre></td></tr></table></figure></p>
<p>返回查找到的元素的第一个:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">soup.select_one(<span class="string">".sister"</span>)</div><div class="line"></div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;对于熟悉CSS选择器语法的人来说这是个非常方便的方法.Beautiful Soup也支持CSS选择器API, 如果你仅仅需要CSS选择器的功能,那么直接使用 lxml 也可以, 而且速度更快,支持更多的CSS选择器语法,但Beautiful Soup整合了CSS选择器的语法和自身方便使用API。</p>
<p>##修改文档树<br>BeautifuSoup的<strong>强项是文档树的搜索</strong>，当同时也可以方便的修改文档树。</p>
<ol>
<li>修改tag的名称和属性</li>
</ol>
<p>&ensp;&ensp;在 Attributes 的章节中已经介绍过这个功能,但是再看一遍也无妨. 重命名一个tag,改变属性的值,添加或删除属性:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">'&lt;b class="boldest"&gt;Extremely bold&lt;/b&gt;'</span>)</div><div class="line">tag = soup.b</div><div class="line">tag.name = <span class="string">"blockquote"</span></div><div class="line">tag[<span class="string">'class'</span>] = <span class="string">'verybold'</span></div><div class="line">tag[<span class="string">'id'</span>] = <span class="number">1</span></div><div class="line">tag</div><div class="line"><span class="comment"># &lt;blockquote class="verybold" id="1"&gt;Extremely bold&lt;/blockquote&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">del</span> tag[<span class="string">'class'</span>]</div><div class="line"><span class="keyword">del</span> tag[<span class="string">'id'</span>]</div><div class="line">tag</div><div class="line"><span class="comment"># &lt;blockquote&gt;Extremely bold&lt;/blockquote&gt;</span></div></pre></td></tr></table></figure></p>
<ol>
<li>修改.string</li>
</ol>
<p>&ensp;&ensp;给tag的 .string 属性赋值,就相当于用当前的内容替代了原来的内容:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">tag = soup.a</div><div class="line">tag.string = <span class="string">"New link text."</span></div><div class="line">tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;New link text.&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<p><strong>注意</strong> 如果当前的tag包含了其它tag，那么给它的 .string 属性赋值会覆盖掉原有的所有内容包括子tag。</p>
<ol>
<li><p>append()<br>&ensp;&ensp;Tag.append() 方法想tag中添加内容,就好像Python的列表的 .append() 方法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">"&lt;a&gt;Foo&lt;/a&gt;"</span>)</div><div class="line">soup.a.append(<span class="string">"Bar"</span>)</div><div class="line">soup</div><div class="line"><span class="comment"># &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;a&gt;FooBar&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;</span></div><div class="line">soup.a.contents</div><div class="line"><span class="comment"># [u'Foo', u'Bar']</span></div></pre></td></tr></table></figure>
</li>
<li><p>NavigableString() 和 .new_tag()</p>
</li>
</ol>
<p>&ensp;&ensp;如果想添加一段文本内容到文档中也没问题,可以调用Python的 append() 方法 或调用 NavigableString 的构造方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">"&lt;b&gt;&lt;/b&gt;"</span>)</div><div class="line">tag = soup.b</div><div class="line">tag.append(<span class="string">"Hello"</span>)</div><div class="line">new_string = NavigableString(<span class="string">" there"</span>)</div><div class="line">tag.append(new_string)</div><div class="line">tag</div><div class="line"><span class="comment"># &lt;b&gt;Hello there.&lt;/b&gt;</span></div><div class="line">tag.contents</div><div class="line"><span class="comment"># [u'Hello', u' there']</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果想要创建一段注释,或 NavigableString 的任何子类, 只要调用 NavigableString 的构造方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> Comment</div><div class="line">new_comment = soup.new_string(<span class="string">"Nice to see you."</span>, Comment)</div><div class="line">tag.append(new_comment)</div><div class="line">tag</div><div class="line"><span class="comment"># &lt;b&gt;Hello there&lt;!--Nice to see you.--&gt;&lt;/b&gt;</span></div><div class="line">tag.contents</div><div class="line"><span class="comment"># [u'Hello', u' there', u'Nice to see you.']</span></div></pre></td></tr></table></figure></p>
<p><strong>这是Beautiful Soup 4.2.1 中新增的方法</strong></p>
<ul>
<li>创建一个tag最好的方法是调用工厂方法 BeautifulSoup.new_tag() :</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">"&lt;b&gt;&lt;/b&gt;"</span>)</div><div class="line">original_tag = soup.b</div><div class="line">new_tag = soup.new_tag(<span class="string">"a"</span>, href=<span class="string">"http://www.example.com"</span>)</div><div class="line">original_tag.append(new_tag)</div><div class="line">original_tag</div><div class="line"><span class="comment"># &lt;b&gt;&lt;a href="http://www.example.com"&gt;&lt;/a&gt;&lt;/b&gt;</span></div><div class="line">new_tag.string = <span class="string">"Link text."</span></div><div class="line">original_tag</div><div class="line"><span class="comment"># &lt;b&gt;&lt;a href="http://www.example.com"&gt;Link text.&lt;/a&gt;&lt;/b&gt;</span></div></pre></td></tr></table></figure>
<p>&ensp;&ensp;第一个参数作为tag的name,是必填,其它参数选填。</p>
<ol>
<li>insert()</li>
</ol>
<p>&ensp;&ensp;Tag.insert() 方法与 Tag.append() 方法类似,区别是不会把新元素添加到父节点 .contents 属性的最后,而是把元素插入到指定的位置.与Python列表总的 .insert() 方法的用法下同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">tag = soup.a</div><div class="line">tag.insert(<span class="number">1</span>, <span class="string">"but did not endorse "</span>)</div><div class="line">tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;I linked to but did not endorse &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;</span></div><div class="line">tag.contents</div><div class="line"><span class="comment"># [u'I linked to ', u'but did not endorse', &lt;i&gt;example.com&lt;/i&gt;]</span></div></pre></td></tr></table></figure></p>
<ol>
<li>insert_before()和insert_after()</li>
</ol>
<p>insert_before() 方法在当前tag或文本节点前插入内容:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">"&lt;b&gt;stop&lt;/b&gt;"</span>)</div><div class="line">tag = soup.new_tag(<span class="string">"i"</span>)</div><div class="line">tag.string = <span class="string">"Don't"</span></div><div class="line">soup.b.string.insert_before(tag)</div><div class="line">soup.b</div><div class="line"><span class="comment"># &lt;b&gt;&lt;i&gt;Don't&lt;/i&gt;stop&lt;/b&gt;</span></div></pre></td></tr></table></figure></p>
<p>insert_after() 方法在当前tag或文本节点后插入内容:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup.b.i.insert_after(soup.new_string(<span class="string">" ever "</span>))</div><div class="line">soup.b</div><div class="line"><span class="comment"># &lt;b&gt;&lt;i&gt;Don't&lt;/i&gt; ever stop&lt;/b&gt;</span></div><div class="line">soup.b.contents</div><div class="line"><span class="comment"># [&lt;i&gt;Don't&lt;/i&gt;, u' ever ', u'stop']</span></div></pre></td></tr></table></figure></p>
<ol>
<li>clear()</li>
</ol>
<p>Tag.clear() 方法移除当前tag的内容:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">tag = soup.a</div><div class="line">tag.clear()</div><div class="line">tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<ol>
<li>extract()</li>
</ol>
<p>PageElement.extract() 方法将当前tag移除文档树,并作为方法结果返回:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">a_tag = soup.a</div><div class="line">i_tag = soup.i.extract()</div><div class="line">a_tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;I linked to&lt;/a&gt;</span></div><div class="line">i_tag</div><div class="line"><span class="comment"># &lt;i&gt;example.com&lt;/i&gt;</span></div><div class="line">print(i_tag.parent)</div><div class="line"><span class="keyword">None</span></div></pre></td></tr></table></figure></p>
<p>这个方法实际上产生了2个文档树: 一个是用来解析原始文档的 BeautifulSoup 对象,另一个是被移除并且返回的tag.被移除并返回的tag可以继续调用 extract 方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">my_string = i_tag.string.extract()</div><div class="line">my_string</div><div class="line"><span class="comment"># u'example.com'</span></div><div class="line">print(my_string.parent)</div><div class="line"><span class="comment"># None</span></div><div class="line">i_tag</div><div class="line"><span class="comment"># &lt;i&gt;&lt;/i&gt;</span></div></pre></td></tr></table></figure></p>
<ol>
<li>decompose()</li>
</ol>
<p>Tag.decompose() 方法将当前节点移除文档树并完全销毁:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">a_tag = soup.a</div><div class="line">soup.i.decompose()</div><div class="line">a_tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;I linked to&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<ol>
<li>replace_with()</li>
</ol>
<p>PageElement.replace_with() 方法移除文档树中的某段内容,并用新tag或文本节点替代它:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">a_tag = soup.a</div><div class="line">new_tag = soup.new_tag(<span class="string">"b"</span>)</div><div class="line">new_tag.string = <span class="string">"example.net"</span></div><div class="line">a_tag.i.replace_with(new_tag)</div><div class="line">a_tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;I linked to &lt;b&gt;example.net&lt;/b&gt;&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<p>replace_with() 方法<strong>返回</strong>被替代的tag或文本节点,可以用来浏览或添加到文档树其它地方.</p>
<ol>
<li><p>wrap()</p>
<p>PageElement.wrap() 方法可以对指定的tag元素进行包装 ,并返回包装后的结果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">"&lt;p&gt;I wish I was bold.&lt;/p&gt;"</span>)</div><div class="line">soup.p.string.wrap(soup.new_tag(<span class="string">"b"</span>))</div><div class="line"><span class="comment"># &lt;b&gt;I wish I was bold.&lt;/b&gt;</span></div><div class="line">soup.p.wrap(soup.new_tag(<span class="string">"div"</span>))</div><div class="line"><span class="comment"># &lt;div&gt;&lt;p&gt;&lt;b&gt;I wish I was bold.&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>注意</strong>该方法在 Beautiful Soup 4.0.5 中添加</p>
<ol>
<li>unwra()<br>Tag.unwrap() 方法与 wrap() 方法相反.将移除tag内的所有tag标签,该方法常被用来进行标记的解包:<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">a_tag = soup.a</div><div class="line">a_tag.i.unwrap()</div><div class="line">a_tag</div><div class="line"><span class="comment"># &lt;a href="http://example.com/"&gt;I linked to example.com&lt;/a&gt;</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>与 replace_with() 方法相同, unwrap() 方法返回被移除的tag</p>
<p>##输出</p>
<ol>
<li>格式化输出</li>
</ol>
<p>&ensp;&ensp;prettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">soup.prettify()</div><div class="line"><span class="comment"># '&lt;html&gt;\n &lt;head&gt;\n &lt;/head&gt;\n &lt;body&gt;\n  &lt;a href="http://example.com/"&gt;\n...'</span></div><div class="line">print(soup.prettify())</div><div class="line"><span class="comment"># &lt;html&gt;</span></div><div class="line"><span class="comment">#  &lt;head&gt;</span></div><div class="line"><span class="comment">#  &lt;/head&gt;</span></div><div class="line"><span class="comment">#  &lt;body&gt;</span></div><div class="line"><span class="comment">#   &lt;a href="http://example.com/"&gt;</span></div><div class="line"><span class="comment">#    I linked to</span></div><div class="line"><span class="comment">#    &lt;i&gt;</span></div><div class="line"><span class="comment">#     example.com</span></div><div class="line"><span class="comment">#    &lt;/i&gt;</span></div><div class="line"><span class="comment">#   &lt;/a&gt;</span></div><div class="line"><span class="comment">#  &lt;/body&gt;</span></div><div class="line"><span class="comment"># &lt;/html&gt;</span></div></pre></td></tr></table></figure></p>
<p>BeautifulSoup 对象和它的tag节点都可以调用 prettify() 方法.</p>
<ol>
<li>压缩输出</li>
</ol>
<p>&ensp;&ensp;如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">str(soup)</div><div class="line"><span class="comment"># '&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;'</span></div><div class="line">unicode(soup.a)</div><div class="line"><span class="comment"># u'&lt;a href="http://example.com/"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;str() 方法返回UTF-8编码的字符串,可以指定 编码 的设置.还可以调用 encode() 方法获得字节码或调用 decode() 方法获得Unicode.</p>
<ol>
<li>输出格式</li>
</ol>
<p>Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“&lquot;”:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(<span class="string">"&amp;ldquo;Dammit!&amp;rdquo; he said."</span>)</div><div class="line">unicode(soup)</div><div class="line"><span class="comment"># u'&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;\u201cDammit!\u201d he said.&lt;/body&gt;&lt;/html&gt;'</span></div></pre></td></tr></table></figure></p>
<p>如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">str(soup)</div><div class="line"><span class="comment"># '&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;\xe2\x80\x9cDammit!\xe2\x80\x9d he said.&lt;/body&gt;&lt;/html&gt;'</span></div></pre></td></tr></table></figure></p>
<ol>
<li>get_text()</li>
</ol>
<p>如果只想得到tag中包含的文本内容,那么可以调用 get_text() 方法,这个方法获取到tag中包含的所有文版内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">'&lt;a href="http://example.com/"&gt;\nI linked to &lt;i&gt;example.com&lt;/i&gt;\n&lt;/a&gt;'</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">soup.get_text()</div><div class="line"><span class="string">u'\nI linked to example.com\n'</span></div><div class="line">soup.i.get_text()</div><div class="line"><span class="string">u'example.com'</span></div></pre></td></tr></table></figure></p>
<p>可以通过参数指定tag的文本内容的分隔符:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># soup.get_text("|")</span></div><div class="line"><span class="string">u'\nI linked to |example.com|\n'</span></div></pre></td></tr></table></figure></p>
<p>还可以去除获得文本内容的前后空白:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># soup.get_text("|", strip=True)</span></div><div class="line"><span class="string">u'I linked to|example.com'</span></div></pre></td></tr></table></figure></p>
<p>或者使用 .stripped_strings 生成器,获得文本列表后手动处理列表:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[text <span class="keyword">for</span> text <span class="keyword">in</span> soup.stripped_strings]</div><div class="line"><span class="comment"># [u'I linked to', u'example.com']</span></div></pre></td></tr></table></figure></p>
<p>##解析器</p>
<ol>
<li>指定文档的解析器</li>
</ol>
<p>&ensp;&ensp;如果仅是想要解析HTML文档,只要用文档创建 BeautifulSoup 对象就可以了.Beautiful Soup会自动选择一个解析器来解析文档.但是还可以通过参数指定使用那种解析器来解析当前文档.</p>
<p>&ensp;&ensp;BeautifulSoup 第一个参数应该是要被解析的文档字符串或是文件句柄,第二个参数用来标识怎样解析文档.如果第二个参数为空,那么Beautiful Soup根据当前系统安装的库自动选择解析器,解析器的优先数序: lxml, html5lib, Python标准库.在下面两种条件下解析器优先顺序会变化:</p>
<ul>
<li>要解析的文档是什么类型: 目前支持, “html”, “xml”, 和 “html5”</li>
<li>指定使用哪种解析器: 目前支持, “lxml”, “html5lib”, 和 “html.parser”<br>&ensp;&ensp;安装解析器 章节介绍了可以使用哪种解析器,以及如何安装.</li>
</ul>
<p>&ensp;&ensp;如果指定的解析器没有安装,Beautiful Soup会自动选择其它方案.目前只有 lxml 解析器支持XML文档的解析,在没有安装lxml库的情况下,创建 beautifulsoup 对象时无论是否指定使用lxml,都无法得到解析后的对象。</p>
<ol>
<li>解析器之间的区别</li>
</ol>
<p>&ensp;&ensp;Beautiful Soup为不同的解析器提供了相同的接口,但解析器本身时有区别的.同一篇文档被不同的解析器解析后可能会生成不同结构的树型文档.区别最大的是HTML解析器和XML解析器,看下面片段被解析成HTML结构:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">BeautifulSoup(<span class="string">"&lt;a&gt;&lt;b /&gt;&lt;/a&gt;"</span>)</div><div class="line"><span class="comment"># &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;a&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;因为空标签b不符合HTML标准，所以解析器把它解析成b&gt;/b<br>&ensp;&ensp;同样的文档使用XML解析如下(解析XML需要安装lxml库).注意,空标签b 依然被保留,并且文档前添加了XML头,而不是被包含在html标签内:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">BeautifulSoup(<span class="string">"&lt;a&gt;&lt;b /&gt;&lt;/a&gt;"</span>, <span class="string">"xml"</span>)</div><div class="line"><span class="comment"># &lt;?xml version="1.0" encoding="utf-8"?&gt;</span></div><div class="line"><span class="comment"># &lt;a&gt;&lt;b/&gt;&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;HTML解析器之间也有区别,如果被解析的HTML文档是标准格式,那么解析器之间没有任何差别,只是解析速度不同,结果都会返回正确的文档树.</p>
<p>&ensp;&ensp;但是如果被解析文档不是标准格式,那么不同的解析器返回结果可能不同.下面例子中,使用lxml解析错误格式的文档,结果p标签被直接忽略掉了:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">BeautifulSoup(<span class="string">"&lt;a&gt;&lt;/p&gt;"</span>, <span class="string">"lxml"</span>)</div><div class="line"><span class="comment"># &lt;html&gt;&lt;body&gt;&lt;a&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;使用html5lib库解析相同的文档会得到不同的结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">BeautifulSoup(<span class="string">"&lt;a&gt;&lt;/p&gt;"</span>, <span class="string">"html5lib"</span>)</div><div class="line"><span class="comment"># &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;a&gt;&lt;p&gt;&lt;/p&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;html5lib库没有忽略掉p标签,而是自动补全了标签,还给文档树添加了head标签.使用pyhton内置库解析结果如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">BeautifulSoup(<span class="string">"&lt;a&gt;&lt;/p&gt;"</span>, <span class="string">"html.parser"</span>)</div><div class="line"><span class="comment"># &lt;a&gt;&lt;/a&gt;</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;与lxml库类似的,Python内置库忽略掉了p标签,与html5lib库不同的是标准库没有尝试创建符合标准的文档格式或将文档片段包含在body标签内,与lxml不同的是标准库甚至连html标签都没有尝试去添加.<br>&ensp;&ensp;因为文档片段“a/p”是错误格式,所以以上解析方式都能算作”正确”,html5lib库使用的是HTML5的部分标准,所以最接近”正确”.不过所有解析器的结构都能够被认为是”正常”的.<br>&ensp;&ensp;不同的解析器可能影响代码执行结果,如果在分发给别人的代码中使用了 BeautifulSoup ,那么最好注明使用了哪种解析器,以减少不必要的麻烦.</p>
<p>##编码<br>&ensp;&ensp;任何HTML或XML文档都有自己的编码方式,比如ASCII 或 UTF-8,但是使用Beautiful Soup解析后,文档都被转换成了Unicode:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">"&lt;h1&gt;Sacr\xc3\xa9 bleu!&lt;/h1&gt;"</span></div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">soup.h1</div><div class="line"><span class="comment"># &lt;h1&gt;Sacré bleu!&lt;/h1&gt;</span></div><div class="line">soup.h1.string</div><div class="line"><span class="comment"># u'Sacr\xe9 bleu!'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;这不是魔术(但很神奇),Beautiful Soup用了 编码自动检测 子库来识别当前文档编码并转换成Unicode编码. BeautifulSoup 对象的 .original_encoding 属性记录了自动识别编码的结果:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">soup.original_encoding</div><div class="line"><span class="string">'utf-8'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;编码自动检测 功能大部分时候都能猜对编码格式,但有时候也会出错.有时候即使猜测正确,也是在逐个字节的遍历整个文档后才猜对的,这样很慢.如果预先知道文档编码,可以设置编码参数来减少自动检查编码出错的概率并且提高文档解析速度.在创建 BeautifulSoup 对象的时候设置 from_encoding 参数.<br>&ensp;&ensp;下面一段文档用了ISO-8859-8编码方式,这段文档太短,结果Beautiful Soup以为文档是用ISO-8859-7编码:<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">markup = b"&lt;h1&gt;\xed\xe5\xec\xf9&lt;/h1&gt;"</div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">soup.h1</div><div class="line">&lt;h1&gt;νεμω&lt;/h1&gt;</div><div class="line">soup.original_encoding</div><div class="line"># 'ISO-8859-7'</div></pre></td></tr></table></figure></p>
<p>通过传入 from_encoding 参数来指定编码方式:<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(markup, from_encoding="iso-8859-8")</div><div class="line">soup.h1</div><div class="line">&lt;h1&gt;םולש&lt;/h1&gt;</div><div class="line">soup.original_encoding</div><div class="line"># 'iso8859-8'</div></pre></td></tr></table></figure></p>
<p>&esnp;&ensp;如果仅知道文档采用了Unicode编码, 但不知道具体编码. 可以先自己猜测, 猜测错误(依旧是乱码)时, 可以把错误编码作为 exclude_encodings 参数, 这样文档就不会尝试使用这种编码了解码了. <strong>译者备注:</strong> 在没有指定编码的情况下, BS会自己猜测编码, 把不正确的编码排除掉, BS就更容易猜到正确编码.<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(markup, exclude_encodings=["ISO-8859-7"])</div><div class="line">soup.h1</div><div class="line">&lt;h1&gt;םולש&lt;/h1&gt;</div><div class="line">soup.original_encoding</div><div class="line"># 'WINDOWS-1255'</div></pre></td></tr></table></figure></p>
<p>&esnp;&ensp;猜测结果是 Windows-1255 编码, 猜测结果可能不够准确, 但是 Windows-1255 编码是 ISO-8859-8 的扩展集, 所以猜测结果已经十分接近了, 并且不影响使用. (exclude_encodings 参数是 4.4.0版本的新功能)</p>
<p>&esnp;&ensp;少数情况下(通常是UTF-8编码的文档中包含了其它编码格式的文件),想获得正确的Unicode编码就不得不将文档中少数特殊编码字符替换成特殊Unicode编码,“REPLACEMENT CHARACTER” (U+FFFD, �) [9] . 如果Beautifu Soup猜测文档编码时作了特殊字符的替换,那么Beautiful Soup会把 UnicodeDammit 或 BeautifulSoup 对象的 .contains_replacement_characters 属性标记为 True .这样就可以知道当前文档进行Unicode编码后丢失了一部分特殊内容字符.如果文档中包含�而 .contains_replacement_characters 属性是 False ,则表示�就是文档中原来的字符,不是转码失败.</p>
<ol>
<li>输出编码</li>
</ol>
<p>&esnp;&ensp;通过Beautiful Soup输出文档时,不管输入文档是什么编码方式,输出编码均为UTF-8编码,下面例子输入文档是Latin-1编码:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">b'''</span></div><div class="line">&lt;html&gt;</div><div class="line">  &lt;head&gt;</div><div class="line">    &lt;meta content="text/html; charset=ISO-Latin-1" http-equiv="Content-type" /&gt;</div><div class="line">  &lt;/head&gt;</div><div class="line">  &lt;body&gt;</div><div class="line">    &lt;p&gt;Sacr\xe9 bleu!&lt;/p&gt;</div><div class="line">  &lt;/body&gt;</div><div class="line">&lt;/html&gt;</div><div class="line">'''</div><div class="line">soup = BeautifulSoup(markup)</div><div class="line">print(soup.prettify())</div><div class="line"><span class="comment"># &lt;html&gt;</span></div><div class="line"><span class="comment">#  &lt;head&gt;</span></div><div class="line"><span class="comment">#   &lt;meta content="text/html; charset=utf-8" http-equiv="Content-type" /&gt;</span></div><div class="line"><span class="comment">#  &lt;/head&gt;</span></div><div class="line"><span class="comment">#  &lt;body&gt;</span></div><div class="line"><span class="comment">#   &lt;p&gt;</span></div><div class="line"><span class="comment">#    Sacré bleu!</span></div><div class="line"><span class="comment">#   &lt;/p&gt;</span></div><div class="line"><span class="comment">#  &lt;/body&gt;</span></div><div class="line"><span class="comment"># &lt;/html&gt;</span></div></pre></td></tr></table></figure></p>
<p>&esnp;&ensp;注意,输出文档中的meta标签的编码设置已经修改成了与输出编码一致的UTF-8.</p>
<p>&esnp;&ensp;如果不想用UTF-8编码输出,可以将编码方式传入 prettify() 方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">print(soup.prettify(<span class="string">"latin-1"</span>))</div><div class="line"><span class="comment"># &lt;html&gt;</span></div><div class="line"><span class="comment">#  &lt;head&gt;</span></div><div class="line"><span class="comment">#   &lt;meta content="text/html; charset=latin-1" http-equiv="Content-type" /&gt;</span></div><div class="line"><span class="comment"># ...</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;还可以调用 BeautifulSoup 对象或任意节点的 encode() 方法,就像Python的字符串调用 encode() 方法一样:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">soup.p.encode(<span class="string">"latin-1"</span>)</div><div class="line"><span class="comment"># '&lt;p&gt;Sacr\xe9 bleu!&lt;/p&gt;'</span></div><div class="line">soup.p.encode(<span class="string">"utf-8"</span>)</div><div class="line"><span class="comment"># '&lt;p&gt;Sacr\xc3\xa9 bleu!&lt;/p&gt;'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果文档中包含当前编码不支持的字符,那么这些字符将呗转换成一系列XML特殊字符引用,下面例子中包含了Unicode编码字符SNOWMAN:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">u"&lt;b&gt;\N&#123;SNOWMAN&#125;&lt;/b&gt;"</span></div><div class="line">snowman_soup = BeautifulSoup(markup)</div><div class="line">tag = snowman_soup.b</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;SNOWMAN字符在UTF-8编码中可以正常显示(看上去像是☃),但有些编码不支持SNOWMAN字符,比如ISO-Latin-1或ASCII,那么在这些编码中SNOWMAN字符会被转换成“&amp;#9731”:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">print(tag.encode(<span class="string">"utf-8"</span>))</div><div class="line"><span class="comment"># &lt;b&gt;☃&lt;/b&gt;</span></div><div class="line"><span class="keyword">print</span> tag.encode(<span class="string">"latin-1"</span>)</div><div class="line"><span class="comment"># &lt;b&gt;&amp;#9731;&lt;/b&gt;</span></div><div class="line"><span class="keyword">print</span> tag.encode(<span class="string">"ascii"</span>)</div><div class="line"><span class="comment"># &lt;b&gt;&amp;#9731;&lt;/b&gt;</span></div></pre></td></tr></table></figure></p>
<ol>
<li>Unicode, Dammit! (乱码, 靠!)</li>
</ol>
<p>&ensp;&ensp;译者备注: UnicodeDammit 是BS内置库, 主要用来猜测文档编码.</p>
<p>&ensp;&ensp;编码自动检测 功能可以在Beautiful Soup以外使用,检测某段未知编码时,可以使用这个方法:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> UnicodeDammit</div><div class="line">dammit = UnicodeDammit(<span class="string">"Sacr\xc3\xa9 bleu!"</span>)</div><div class="line">print(dammit.unicode_markup)</div><div class="line"><span class="comment"># Sacré bleu!</span></div><div class="line">dammit.original_encoding</div><div class="line"><span class="comment"># 'utf-8'</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果Python中安装了 chardet 或 cchardet 那么编码检测功能的准确率将大大提高. 输入的字符越多,检测结果越精确,如果事先猜测到一些可能编码, 那么可以将猜测的编码作为参数,这样将优先检测这些编码:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">dammit = UnicodeDammit(<span class="string">"Sacr\xe9 bleu!"</span>, [<span class="string">"latin-1"</span>, <span class="string">"iso-8859-1"</span>])</div><div class="line">print(dammit.unicode_markup)</div><div class="line"><span class="comment"># Sacré bleu!</span></div><div class="line">dammit.original_encoding</div><div class="line"><span class="comment"># 'latin-1'</span></div></pre></td></tr></table></figure></p>
<ol>
<li>智能引导</li>
</ol>
<p>使用Unicode时,Beautiful Soup还会智能的把引号  转换成HTML或XML中的特殊字符:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">b"&lt;p&gt;I just \x93love\x94 Microsoft Word\x92s smart quotes&lt;/p&gt;"</span></div><div class="line">UnicodeDammit(markup, [<span class="string">"windows-1252"</span>], smart_quotes_to=<span class="string">"html"</span>).unicode_markup</div><div class="line"><span class="comment"># u'&lt;p&gt;I just &amp;ldquo;love&amp;rdquo; Microsoft Word&amp;rsquo;s smart quotes&lt;/p&gt;'</span></div><div class="line">UnicodeDammit(markup, [<span class="string">"windows-1252"</span>], smart_quotes_to=<span class="string">"xml"</span>).unicode_markup</div><div class="line"><span class="comment"># u'&lt;p&gt;I just &amp;#x201C;love&amp;#x201D; Microsoft Word&amp;#x2019;s smart quotes&lt;/p&gt;'</span></div></pre></td></tr></table></figure></p>
<p>也可以把引号转换为ASCII码:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">UnicodeDammit(markup, [<span class="string">"windows-1252"</span>], smart_quotes_to=<span class="string">"ascii"</span>).unicode_markup</div><div class="line"><span class="comment"># u'&lt;p&gt;I just "love" Microsoft Word\'s smart quotes&lt;/p&gt;'</span></div></pre></td></tr></table></figure></p>
<p>很有用的功能,但是Beautiful Soup没有使用这种方式.默认情况下,Beautiful Soup把引号转换成Unicode:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">UnicodeDammit(markup, [<span class="string">"windows-1252"</span>]).unicode_markup</div><div class="line"><span class="comment"># u'&lt;p&gt;I just \u201clove\u201d Microsoft Word\u2019s smart quotes&lt;/p&gt;'</span></div></pre></td></tr></table></figure></p>
<ol>
<li>矛盾的编码</li>
</ol>
<p>&ensp;&ensp;有时文档的大部分都是用UTF-8,但同时还包含了Windows-1252编码的字符,就像微软的智能引号 一样. 一些包含多个信息的来源网站容易出现这种情况. UnicodeDammit.detwingle() 方法可以把这类文档转换成纯UTF-8编码格式,看个简单的例子:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">snowmen = (<span class="string">u"\N&#123;SNOWMAN&#125;"</span> * <span class="number">3</span>)</div><div class="line">quote = (<span class="string">u"\N&#123;LEFT DOUBLE QUOTATION MARK&#125;I like snowmen!\N&#123;RIGHT DOUBLE QUOTATION MARK&#125;"</span>)</div><div class="line">doc = snowmen.encode(<span class="string">"utf8"</span>) + quote.encode(<span class="string">"windows_1252"</span>)</div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;这段文档很杂乱,snowmen是UTF-8编码,引号是Windows-1252编码,直接输出时不能同时显示snowmen和引号,因为它们编码不同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">print(doc)</div><div class="line"><span class="comment"># ☃☃☃�I like snowmen!�</span></div><div class="line"></div><div class="line">print(doc.decode(<span class="string">"windows-1252"</span>))</div><div class="line"><span class="comment"># â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;如果对这段文档用UTF-8解码就会得到 UnicodeDecodeError 异常,如果用Windows-1252解码就回得到一堆乱码. 幸好, UnicodeDammit.detwingle() 方法会吧这段字符串转换成UTF-8编码,允许我们同时显示出文档中的snowmen和引号:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">new_doc = UnicodeDammit.detwingle(doc)</div><div class="line">print(new_doc.decode(<span class="string">"utf8"</span>))</div><div class="line"><span class="comment"># ☃☃☃“I like snowmen!”</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;UnicodeDammit.detwingle() 方法只能解码包含在UTF-8编码中的Windows-1252编码内容,但这解决了最常见的一类问题.</p>
<p>&ensp;&ensp;在创建 BeautifulSoup 或 UnicodeDammit 对象前一定要先对文档调用 UnicodeDammit.detwingle() 确保文档的编码方式正确.如果尝试去解析一段包含Windows-1252编码的UTF-8文档,就会得到一堆乱码,比如: â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”.<br>&ensp;&ensp;UnicodeDammit.detwingle() 方法在Beautiful Soup 4.1.0版本中新增</p>
<p>###比较对象是否相同<br>&ensp;&ensp;两个 NavigableString 或 Tag 对象具有相同的HTML或XML结构时, Beautiful Soup就判断这两个对象相同. 这个例子中, 2个 b标签在 BS 中是相同的, 尽管他们在文档树的不同位置, 但是具有相同的表象: “b pizza /b”<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">markup = <span class="string">"&lt;p&gt;I want &lt;b&gt;pizza&lt;/b&gt; and more &lt;b&gt;pizza&lt;/b&gt;!&lt;/p&gt;"</span></div><div class="line">soup = BeautifulSoup(markup, <span class="string">'html.parser'</span>)</div><div class="line">first_b, second_b = soup.find_all(<span class="string">'b'</span>)</div><div class="line"><span class="keyword">print</span> first_b == second_b</div><div class="line"><span class="comment"># True</span></div><div class="line"><span class="keyword">print</span> first_b.previous_element == second_b.previous_element</div><div class="line"><span class="comment"># False</span></div></pre></td></tr></table></figure></p>
<p>如果想判断两个对象是否严格的指向同一个对象可以通过 is 来判断<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> first_b <span class="keyword">is</span> second_b</div><div class="line"><span class="comment"># False</span></div></pre></td></tr></table></figure></p>
<p>###复制Beautiful Soup对象<br>copy.copy() 方法可以复制任意 Tag 或 NavigableString 对象<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> copy</div><div class="line">p_copy = copy.copy(soup.p)</div><div class="line"><span class="keyword">print</span> p_copy</div><div class="line"><span class="comment"># &lt;p&gt;I want &lt;b&gt;pizza&lt;/b&gt; and more &lt;b&gt;pizza&lt;/b&gt;!&lt;/p&gt;</span></div></pre></td></tr></table></figure></p>
<p>复制后的对象跟与对象是相等的, 但指向不同的内存地址<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> soup.p == p_copy</div><div class="line"><span class="comment"># True</span></div><div class="line"><span class="keyword">print</span> soup.p <span class="keyword">is</span> p_copy</div><div class="line"><span class="comment"># False</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;源对象和复制对象的区别是源对象在文档树中, 而复制后的对象是独立的还没有添加到文档树中. 复制后对象的效果跟调用了 extract() 方法相同.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> p_copy.parent</div><div class="line"><span class="comment"># None</span></div></pre></td></tr></table></figure></p>
<p>这是因为相等的对象不能同时插入相同的位置</p>
<p>###解析部分文档<br>&ensp;&ensp;如果仅仅因为想要查找文档中的a&gt;标签而将整片文档进行解析,实在是浪费内存和时间.最快的方法是从一开始就把a&gt;标签以外的东西都忽略掉. SoupStrainer 类可以定义文档的某段内容,这样搜索文档时就不必先解析整篇文档,只会解析在 SoupStrainer 中定义过的文档. 创建一个 SoupStrainer 对象并作为 parse_only 参数给 BeautifulSoup 的构造方法即可</p>
<ol>
<li>SoupStrainer<br>&ensp;&ensp;SoupStrainer 类接受与典型搜索方法相同的参数：name , attrs , recursive , string , **kwargs 。下面举例说明三种 SoupStrainer 对象：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> SoupStrainer</div><div class="line">only_a_tags = SoupStrainer(<span class="string">"a"</span>)</div><div class="line">only_tags_with_id_link2 = SoupStrainer(id=<span class="string">"link2"</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_short_string</span><span class="params">(string)</span>:</span></div><div class="line">    <span class="keyword">return</span> len(string) &lt; <span class="number">10</span></div><div class="line">only_short_strings = SoupStrainer(string=is_short_string)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>再拿“爱丽丝”文档来举例，来看看使用三种 SoupStrainer 对象做参数会有什么不同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">html_doc = <span class="string">"""</span></div><div class="line">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</div><div class="line">    &lt;body&gt;</div><div class="line">&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</div><div class="line">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</div><div class="line">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;,</div><div class="line">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</div><div class="line">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</div><div class="line">and they lived at the bottom of a well.&lt;/p&gt;</div><div class="line">&lt;p class="story"&gt;...&lt;/p&gt;</div><div class="line">"""</div><div class="line">print(BeautifulSoup(html_doc, <span class="string">"html.parser"</span>, parse_only=only_a_tags).prettify())</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;</span></div><div class="line"><span class="comment">#  Elsie</span></div><div class="line"><span class="comment"># &lt;/a&gt;</span></div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;</span></div><div class="line"><span class="comment">#  Lacie</span></div><div class="line"><span class="comment"># &lt;/a&gt;</span></div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;</span></div><div class="line"><span class="comment">#  Tillie</span></div><div class="line"><span class="comment"># &lt;/a&gt;</span></div><div class="line">print(BeautifulSoup(html_doc, <span class="string">"html.parser"</span>, parse_only=only_tags_with_id_link2).prettify())</div><div class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;</span></div><div class="line"><span class="comment">#  Lacie</span></div><div class="line"><span class="comment"># &lt;/a&gt;</span></div><div class="line">print(BeautifulSoup(html_doc, <span class="string">"html.parser"</span>, parse_only=only_short_strings).prettify())</div><div class="line"><span class="comment"># Elsie</span></div><div class="line"><span class="comment"># ,</span></div><div class="line"><span class="comment"># Lacie</span></div><div class="line"><span class="comment"># and</span></div><div class="line"><span class="comment"># Tillie</span></div><div class="line"><span class="comment"># ...</span></div><div class="line"><span class="comment">#</span></div></pre></td></tr></table></figure></p>
<p>还可以将 SoupStrainer 作为参数传入 搜索文档树 中提到的方法.这可能不是个常用用法,所以还是提一下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(html_doc)</div><div class="line">soup.find_all(only_short_strings)</div><div class="line"><span class="comment"># [u'\n\n', u'\n\n', u'Elsie', u',\n', u'Lacie', u' and\n', u'Tillie',</span></div><div class="line"><span class="comment">#  u'\n\n', u'...', u'\n']</span></div></pre></td></tr></table></figure></p>
<p>###常见问题</p>
<ol>
<li>代码诊断</li>
</ol>
<p>&ensp;&ensp;如果想知道Beautiful Soup到底怎样处理一份文档,可以将文档传入 diagnose() 方法(Beautiful Soup 4.2.0中新增),Beautiful Soup会输出一份报告,说明不同的解析器会怎样处理这段文档,并标出当前的解析过程会使用哪种解析器:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4.diagnose <span class="keyword">import</span> diagnose</div><div class="line">data = open(<span class="string">"bad.html"</span>).read()</div><div class="line">diagnose(data)</div><div class="line"></div><div class="line"><span class="comment"># Diagnostic running on Beautiful Soup 4.2.0</span></div><div class="line"><span class="comment"># Python version 2.7.3 (default, Aug  1 2012, 05:16:07)</span></div><div class="line"><span class="comment"># I noticed that html5lib is not installed. Installing it may help.</span></div><div class="line"><span class="comment"># Found lxml version 2.3.2.0</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Trying to parse your data with html.parser</span></div><div class="line"><span class="comment"># Here's what html.parser did with the document:</span></div><div class="line"><span class="comment"># ...</span></div></pre></td></tr></table></figure></p>
<p>&ensp;&ensp;diagnose() 方法的输出结果可能帮助你找到问题的原因,如果不行,还可以把结果复制出来以便寻求他人的帮助.</p>
<ol>
<li>文档解析错误</li>
</ol>
<p>&ensp;&ensp;文档解析错误有两种.<strong>一种</strong>是崩溃,Beautiful Soup尝试解析一段文档结果却抛除了异常,通常是 HTMLParser.HTMLParseError;<strong>一种</strong>异常情况,是Beautiful Soup解析后的文档树看起来与原来的内容相差很多.</p>
<p>&ensp;&ensp;这些错误几乎都不是Beautiful Soup的原因,这不是因为Beautiful Soup得代码写的太优秀,而是因为Beautiful Soup没有包含任何文档解析代码.异常产生自被依赖的解析器,如果解析器不能很好的解析出当前的文档,那么最好的办法是换一个解析器.更多细节查看 安装解析器 章节.</p>
<p>&ensp;&ensp;最常见的解析错误是 HTMLParser.HTMLParseError: malformed start tag 和 HTMLParser.HTMLParseError: bad end tag .这都是由Python内置的解析器引起的,解决方法是 安装lxml或html5lib</p>
<p>&ensp;&ensp;最常见的异常现象是当前文档找不到指定的Tag,而这个Tag光是用眼睛就足够发现的了. find_all() 方法返回 [] ,而 find() 方法返回 None .这是Python内置解析器的又一个问题: 解析器会跳过那些它不知道的tag.解决方法还是 安装lxml或html5lib</p>
<ol>
<li>版本错误</li>
</ol>
<p>;</p>
<ul>
<li>SyntaxError: Invalid syntax (异常位置在代码行: ROOT_TAG_NAME = u’[document]’ ),因为Python2版本的代码没有经过迁移就在Python3中窒息感</li>
<li>ImportError: No module named HTMLParser 因为在Python3中执行Python2版本的Beautiful Soup</li>
<li>ImportError: No module named html.parser 因为在Python2中执行Python3版本的Beautiful Soup</li>
<li>ImportError: No module named BeautifulSoup 因为在没有安装BeautifulSoup3库的Python环境下执行代码,或忘记了BeautifulSoup4的代码需要从 bs4 包中引入</li>
<li>ImportError: No module named bs4 因为当前Python环境下还没有安装BeautifulSoup4</li>
</ul>
<p>###解析成XML</p>
<p>&ensp;&ensp;默认情况下,Beautiful Soup会将当前文档作为HTML格式解析,如果要解析XML文档,要在 BeautifulSoup 构造方法中加入第二个参数 “xml”:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(markup, <span class="string">"xml"</span>)</div></pre></td></tr></table></figure></p>
<p>当然,还需要 <a href="http://doc.iplaypy.com/bs4/#id8" target="_blank" rel="external">安装lxml</a><br><strong>解析器的错误</strong></p>
<ul>
<li>如果同样的代码在不同环境下结果不同,可能是因为两个环境下使用不同的解析器造成的.例如这个环境中安装了lxml,而另一个环境中只有html5lib, 解析器之间的区别 中说明了原因.修复方法是在 BeautifulSoup 的构造方法中中指定解析器</li>
<li>因为HTML标签是 大小写敏感 的,所以3种解析器再出来文档时都将tag和属性转换成小写.例如文档中的 TAG会被转换为 tag.如果想要保留tag的大写的话,那么应该将文档 解析成XML .</li>
</ul>
<p><strong>杂项错误</strong></p>
<ul>
<li>UnicodeEncodeError: ‘charmap’ codec can’t encode character u’\xfoo’ in position bar (或其它类型的 UnicodeEncodeError )的错误,主要是两方面的错误(都不是Beautiful Soup的原因),第一种是正在使用的终端(console)无法显示部分Unicode,参考 Python wiki ,第二种是向文件写入时,被写入文件不支持部分Unicode,这时只要用 u.encode(“utf8”) 方法将编码转换为UTF-8.</li>
<li>KeyError: [attr] 因为调用 tag[‘attr’] 方法而引起,因为这个tag没有定义该属性.出错最多的是 KeyError: ‘href’ 和 KeyError: ‘class’ .<strong>如果不确定某个属性是否存在时,用 tag.get(‘attr’) 方法去获取它,跟获取Python字典的key一样</strong></li>
<li>AttributeError: ‘ResultSet’ object has no attribute ‘foo’ 错误通常是因为把 find_all() 的返回结果当作一个tag或文本节点使用,实际上返回结果是一个列表或 ResultSet 对象的字符串,需要对结果进行循环才能得到每个节点的 .foo 属性.或者使用 find() 方法仅获取到一个节点</li>
<li>AttributeError: ‘NoneType’ object has no attribute ‘foo’ 这个错误通常是在调用了 find() 方法后直节点取某个属性 .foo 但是 find() 方法并没有找到任何结果,所以它的返回值是 None .需要找出为什么 find() 的返回值是 None .</li>
</ul>
<p><strong>如何提高效率</strong></p>
<p>&ensp;&ensp;Beautiful Soup对文档的解析速度不会比它所依赖的解析器更快,如果对计算时间要求很高或者计算机的时间比程序员的时间更值钱,那么就应该直接使用 lxml .<br>&ensp;&ensp;换句话说,还有提高Beautiful Soup效率的办法,使用lxml作为解析器.Beautiful Soup用lxml做解析器比用html5lib或Python内置解析器速度快很多.<br>&ensp;&ensp;安装 cchardet 后文档的解码的编码检测会速度更快<br>&ensp;&ensp;<strong>解析部分文档</strong> 不会节省多少解析时间,但是会节省很多内存,并且搜索时也会变得更快.</p>
<p><strong>需要的解析器</strong><br>&ensp;&ensp;Beautiful Soup 3曾使用Python的 SGMLParser 解析器,这个模块在Python3中已经被移除了.Beautiful Soup 4默认使用系统的 html.parser ,也可以使用lxml或html5lib扩展库代替.查看 安装解析器 章节</p>
<p>&ensp;&ensp;因为解析器 html.parser 与 SGMLParser 不同. BS4 和 BS3 处理相同的文档会产生不同的对象结构. 使用lxml或html5lib解析文档的时候, 如果添加了 html.parser 参数, 解析的对象又回发生变化. 如果发生了这种情况, 只能修改对应的处文档结果处理代码了.</p>
<p><strong>方法名的变化</strong></p>
<ul>
<li>renderContents -&gt; encode_contents</li>
<li>replaceWith -&gt; replace_with</li>
<li>replaceWithChildren -&gt; unwrap</li>
<li>findAll -&gt; find_all</li>
<li>findAllNext -&gt; find_all_next</li>
<li>findAllPrevious -&gt; find_all_previous</li>
<li>findNext -&gt; find_next</li>
<li>findNextSibling -&gt; find_next_sibling</li>
<li>findNextSiblings -&gt; find_next_siblings</li>
<li>findParent -&gt; find_parent</li>
<li>findParents -&gt; find_parents</li>
<li>findPrevious -&gt; find_previous</li>
<li>findPreviousSibling -&gt; find_previous_sibling</li>
<li>findPreviousSiblings -&gt; find_previous_siblings</li>
<li>nextSibling -&gt; next_sibling</li>
<li>previousSibling -&gt; previous_sibling</li>
</ul>
<p>Beautiful Soup构造方法的参数部分也有名字变化:</p>
<ul>
<li>BeautifulSoup(parseOnlyThese=…) -&gt; BeautifulSoup(parse_only=…)</li>
<li>BeautifulSoup(fromEncoding=…) -&gt; BeautifulSoup(from_encoding=…)</li>
</ul>
<p>为了适配Python3,修改了一个方法名:</p>
<ul>
<li>Tag.has_key() -&gt; Tag.has_attr()</li>
</ul>
<p>修改了一个属性名,让它看起来更专业点:</p>
<ul>
<li>Tag.isSelfClosing -&gt; Tag.is_empty_element</li>
</ul>
<p>&ensp;&ensp;修改了下面3个属性的名字,以免与Python保留字冲突.这些变动不是向下兼容的,如果在BS3中使用了这些属性,那么在BS4中这些代码无法执行.</p>
<ul>
<li>UnicodeDammit.Unicode -&gt; UnicodeDammit.Unicode_markup``</li>
<li>Tag.next -&gt; Tag.next_element</li>
<li>Tag.previous -&gt; Tag.previous_element</li>
</ul>
<p><strong>生成器</strong><br>&ensp;&ensp;将下列生成器按照PEP8标准重新命名,并转换成对象的属性:</p>
<ul>
<li>childGenerator() -&gt; children</li>
<li>nextGenerator() -&gt; next_elements</li>
<li>nextSiblingGenerator() -&gt; next_siblings</li>
<li>previousGenerator() -&gt; previous_elements</li>
<li>previousSiblingGenerator() -&gt; previous_siblings</li>
<li>recursiveChildGenerator() -&gt; descendants</li>
<li>parentGenerator() -&gt; parents</li>
</ul>
<p>&ensp;&ensp;BS3中有的生成器循环结束后会返回 None 然后结束.这是个bug.新版生成器不再返回 None .</p>
<p>&ensp;&ensp;BS4中增加了2个新的生成器, .strings 和 stripped_strings . .strings 生成器返回NavigableString对象, .stripped_strings 方法返回去除前后空白的Python的string对象.</p>
<p><strong>XML</strong></p>
<p>&ensp;&ensp;BS4中移除了解析XML的 BeautifulStoneSoup 类.如果要解析一段XML文档,使用 BeautifulSoup 构造方法并在第二个参数设置为“xml”.同时 BeautifulSoup 构造方法也不再识别 isHTML 参数.</p>
<p>&ensp;&ensp;Beautiful Soup处理XML空标签的方法升级了.旧版本中解析XML时必须指明哪个标签是空标签. 构造方法的 selfClosingTags 参数已经不再使用.新版Beautiful Soup将所有空标签解析为空元素,如果向空元素中添加子节点,那么这个元素就不再是空元素了.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://cattlefoot.github.io/2017/05/08/python第三方库beatifulSoup使用/" data-id="cjhrczp4p001hlvs65i8jbuyr" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/05/07/python的List与tuple操作方法详解/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          python的List与tuple操作方法详解
        
      </div>
    </a>
  
  
    <a href="/2017/05/10/raspberryWithPython/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">raspberryWithPython</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/7/">7</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bitmap/">Bitmap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BitmapFactory/">BitmapFactory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Download-Manager/">Download Manager</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DynamicLoadApk/">DynamicLoadApk</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Instant-Run/">Instant Run</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MVC-MVP-MVVM/">MVC MVP MVVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MulitiDex/">MulitiDex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NestedScrolling/">NestedScrolling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Options/">Options</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Small/">Small</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Support/">Support</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/7/" style="font-size: 10px;">7</a> <a href="/tags/Android/" style="font-size: 20px;">Android</a> <a href="/tags/Bitmap/" style="font-size: 10px;">Bitmap</a> <a href="/tags/BitmapFactory/" style="font-size: 10px;">BitmapFactory</a> <a href="/tags/Download-Manager/" style="font-size: 15px;">Download Manager</a> <a href="/tags/DynamicLoadApk/" style="font-size: 10px;">DynamicLoadApk</a> <a href="/tags/Instant-Run/" style="font-size: 10px;">Instant Run</a> <a href="/tags/MVC-MVP-MVVM/" style="font-size: 10px;">MVC MVP MVVM</a> <a href="/tags/MulitiDex/" style="font-size: 10px;">MulitiDex</a> <a href="/tags/NestedScrolling/" style="font-size: 10px;">NestedScrolling</a> <a href="/tags/Options/" style="font-size: 10px;">Options</a> <a href="/tags/Small/" style="font-size: 10px;">Small</a> <a href="/tags/Support/" style="font-size: 10px;">Support</a> <a href="/tags/Tool/" style="font-size: 15px;">Tool</a> <a href="/tags/git/" style="font-size: 10px;">git</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/15/mvc-mvp和mvvm理解/">mvc_mvp和mvvm理解</a>
          </li>
        
          <li>
            <a href="/2017/06/28/插件化种种和思考/">插件化种种和思考</a>
          </li>
        
          <li>
            <a href="/2017/06/28/nestedscollin原理/">nestedscollin原理</a>
          </li>
        
          <li>
            <a href="/2017/06/24/downloadManagerSupport7-0/">downloadManagerSupport7.0</a>
          </li>
        
          <li>
            <a href="/2017/06/24/git命令和使用/">git命令和使用</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 CallteFoot<br>
      Propulsé by <a href="https://cattlefoot.github.io" target="_blank">CallteFoot</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>